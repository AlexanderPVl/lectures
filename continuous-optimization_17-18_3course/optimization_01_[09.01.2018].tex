\documentclass[a4paper, 12pt]{article}
%\input{header.sty}

\begin{document}
%\maketitle

\section{Лекция 1}

Мы будем учиться решать задачи вида $$f(x) \rightarrow \min_{x},$$ работать с $x \in \mathbb{R}^n$, а также считать, что функция $f$ гладкая, т.е. $f \in C^1(\mathbb{R}^n)$. Напомним, что $f \in C^m(X)$, если $f$ определена на множестве $X$ и имеет непрерывные производные всех порядков до $m$ включительно.

Мы часто будем обращаться к понятиям градиента и гессиана функции, так что давайте напомним, что это такое. \textit{Градиентом} функции $f(x) = f(x_1, ..., x_n)$ называется вектор (в курсе под вектором всегда будет пониматься вектор-столбец) всех её частных производных:
$$\nabla f = \left(\frac{\partial f}{\partial x_i}\right)_{i=1}^{n} = \left(\frac{\partial f}{\partial x_1}, \dots, \frac{\partial f}{\partial x_n} \right)^T \text{,}$$
а её \textit{гессианом} называется матрица, составленная из частных производных второго порядка:
\begin{equation*} \nabla^2 f = \left(\frac{\partial^2 f}{\partial x_i \partial x_j}\right)_{i=1, j=1}^{n, n} = 
\begin{pmatrix}
  \frac{\partial^2 f}{\partial x_1 \partial x_1}& \dots & \frac{\partial^2 f}{\partial x_1 \partial x_n}\\
  \vdots & \ddots & \vdots \\
  \frac{\partial^2 f}{\partial x_n \partial x_1}& \dots & \frac{\partial^2 f}{\partial x_n \partial x_n}
\end{pmatrix}
\end{equation*}


\subsection{Необходимые и достаточные условия локального минимума}
Вспомним необходимые и достаточные условия для точки локального минимума дважды непрерывно дифференцируемой функции.

\begin{Theorem} Имеют место следующие необходимое и достаточное условия локального минимума:
\begin{enumerate}
    \item Пусть $f \in C^2(\mathbb{R}^n)$, а $x_0 \in \opint \dom f$ --- точка локального минимума. Тогда $\nabla f(x_0) = 0$ и $\nabla^2 f(x_0) \geq 0$. 
    \item Пусть $f \in C^2(\mathbb{R}^n)$, а $x_0 \in \opint \dom f$ такая, что $\nabla f(x_0) = 0$ и $\nabla^2 f(x_0) > 0$. Тогда $x_0$ --- точка локального минимума.
\end{enumerate}
\end{Theorem}
\begin{Comment}
    $\dom f$ --- множество, на котором определена функция $f$, а $\opint A$ --- множество внутренних точек множества $A$ (точка называется внутренней, если найдется её окрестность, целиком лежащая в $A$). Получаем, что $\opint \dom f$ --- множество всех внутренних точек области определения $f$.
\end{Comment}

Докажем, например, первое утверждение.
\begin{proof}
Из определения локального минимума, найдётся такая окрестность $U_{\varepsilon}(x_0)$, что $\forall x \in U_{\varepsilon}(x_0) \Rightarrow f(x) \geq f(x_0)$.

Рассмотрим функцию $\varphi(\alpha) = f(x_0 + \alpha d)$, где $\alpha \in \mathbb{R}_{+}$ --- положительное вещественное число, а $d \in \mathbb{R}^n$. По теореме о производной сложной функции найдем производную $\varphi'(0)$ (тут мы воспользовались тем, что $f$ дифференцируема):
$$\varphi'(0) = \sum_{i=1}^{n} \frac{\partial f}{\partial x_{0i}} d_i = \nabla f(x_0)^T d$$

Разложим $\varphi(\alpha)$ в ряд Тейлора в окрестности нуля: $$\varphi(\alpha) = \varphi(0) + \varphi'(0) \alpha + o(\alpha)\text{,}$$
а значит
$$f(x_0 + \alpha d) = f(x_0) + \alpha \nabla f(x_0)^T d + o(\alpha)$$

Из определения окрестности найдется такое $\alpha_{\text{max}}$, что $x_0 + \alpha d \in U_{\varepsilon}(x_0)$ для $0 < \alpha \leq \alpha_{\text{max}}$, а значит для таких $\alpha$ выполнено
$$\alpha \nabla f(x_0)^T d + o(\alpha) = f(x_0 + \alpha d) - f(x_0) \geq 0 \Rightarrow \text{\{делим на $\alpha > 0$\}} \Rightarrow \nabla f(x_0)^T d + o(1) \geq 0$$

В пределе при $\alpha \rightarrow 0$ получим $\nabla f(x_0)^T d  \geq 0$ для любого $d$ (тут мы воспользовались тем, что $x_0 \in \opint \dom f$), в том числе и для $-d$, т.е. на самом деле $\nabla f(x_0)^T d = 0$ для любого $d$. А это возможно только лишь тогда, когда $\nabla f(x_0) = 0$.

Заметим, что мы пока воспользовались лишь тем, что $f \in C^1(\mathbb{R}^n)$, и никак не использовали то, что $f \in C^2(\mathbb{R}^n)$. Давайте найдем этому применение и разложим функцию $\varphi(\alpha)$ в ряд Тейлора до второй степени:
$$\varphi(\alpha) = \varphi(0) + \underbrace{\varphi'(0)}_{=0} + \frac{1}{2}\varphi''(0) \alpha^2 + o(\alpha^2) = \varphi(0) + \underbrace{\varphi'(0)}_{=0} + \frac{1}{2}\varphi''(0) \alpha^2 + o(\alpha^2)$$
Воспользовавшись еще раз теоремой о производной сложной функции, найдем 
$$\varphi''(0) = d^T \left[ \nabla^2 f(x_0) \right]d\text{,}$$
а значит
$$\frac{1}{2}\varphi''(0) \alpha^2 + o(\alpha^2) = f(x_0 + \alpha d) - f(x_0) \geq 0 \Rightarrow d^T \left[ \nabla^2 f(x_0) \right]d + o(1) \geq 0$$
и после предельного перехода при $\alpha \rightarrow 0$ получим, что для любых $d$ выполнено $d^T \left[ \nabla^2 f(x_0) \right]d \geq 0$, что и означает, что $\nabla^2 f(x_0) \geq 0$.

\end{proof}

\subsection{Машинная точность и разностная производная}
Вспомним, как мы кодируем представление вещественных чисел в памяти компьютера. Один бит определяет знак числа: $s \in \{-1, +1\}$, еще несколько бит определяют мантиссу $M$, а остальные биты кодируют степень $E$ так, что представление вещественного числа $x$
$$\fl(x) = s\cdot M\cdot 2^E$$

Очевидно, мы не можем представить всю вещественную прямую таким кодированием, и для пары различных чисел $x_1$ и $x_2$ может оказаться, что $\fl(x_1) = \fl(x_2)$. Заметим также, что закодированные точки <<сгущаются>> около нуля. При использовании такого представления возможны неточности в арифметических вычислениях. Например, если мы к очень большому числу (с большой положительной степенью) прибавим очень маленькое число (с отрицательной степенью), результат будет равен первому числу в силу ограничений на размер мантиссы. Однако стоит отметить, что при произведении чисел и их делении потерь в точности практически нет.

\textit{Машинной точностью} называется такое число $\varepsilon_m$, что
$$\forall x \Rightarrow \left| \frac{\fl(x) - x}{x}\right| \leq \varepsilon_m$$

На самом деле, машинная точность показывает, каким числом можно ограничить абсолютную погрешность мантиссы сверху. Для чисел с одинарной точностью $\varepsilon_m \approx 10^{-7}$, с двойной точностью --- $\varepsilon_m \approx 10^{-16}$. 

Нам часто придется программно реализовывать функции, которые вычисляют градиенты. Чтобы проверить себя и поймать возможные ошибки, пользуются численным нахождением градиента. Коль скоро функция $f$ дифференцируема, мы можем разложить её в ряд Тейлора:
$$f(x_0 + \varepsilon d) = f(x_0) + \varepsilon \nabla f(x_0)^T d + o(\varepsilon)$$
запишем
$$f(x_0 + \varepsilon d) \approx f(x_0) + \varepsilon \nabla f(x_0)^T d \Rightarrow \nabla f(x_0)^T d \approx \frac{f(x_0 + \varepsilon d) - f(x_0)}{\varepsilon}$$
Возьмем в качестве вектора $d$ векторную единицу $e_i$, т.е. вектор, в котором все координаты, кроме $i$-ой равны нулю, а $i$-ая равна единице. Тогда получим, что 
$$\frac{\partial f}{\partial x_i}(x_0) = \nabla f(x_0)^T e_i \approx \frac{f(x_0 + \varepsilon e_i) - f(x_0)}{\varepsilon}$$

Заметим, что $\varepsilon$ не может быть слишком большим (будут слишком большие погрешности) или слишком маленьким (тогда в числителе дроби производится вычитание двух близких друг к другу чисел, и мы опять сталкивамся с неточностью арифметики чисел с плавающей точкой). В качестве $\varepsilon$ рекомендуется брать корень из машинной точности $\sqrt{\varepsilon_m}$. Напрмер, для типа \textsf{double} рекомендуется брать $\varepsilon$ из диапазона $[10^{-7}, 10^{-8}]$.

\subsection{Классы функций}
Выделим несколько классов функций, к которым в дальнейшем будем обращаться.
\begin{enumerate}
    \item \textbf{Выпуклые функции}. Дадим уже знакомое нам
    \begin{Def}
    Функция $f$ называется выпуклой, если для любых $x, y \in \dom f$ и любого $\alpha \in [0, 1]$ выполняется неравенство $f(\alpha x + (1-\alpha) y) \leq \alpha f(x) + (1 - \alpha)f(y)$.
    \end{Def}
    Геометрически это означает, что график функции лежит не выше хорды, стягивающей две любые точки $x$ и $y$. Однако существует эквивалентное определение выпуклой функции через касательные.
    \begin{Def}
    Функция $f$ называется выпуклой, если для любых $x, y \in \dom f$ выполняется неравенство $f(y) \geq f(x) + \nabla f(x)^T (y-x)$.
    \end{Def}
    Заметим, что выражение, стоящее в правой части неравенства определяет касательную к графику функции, проведенную в точке $x$. Неравенство же означает, что график функции лежит не ниже любой касательной к этому графику, в какой бы точке она бы ни была проведена.
    
    \item \textbf{Сильно выпуклые функции}. Теперь давайте требовать, чтобы график функции лежал не ниже касательной \textit{параболы} кривизны $\mu > 0$.
    \begin{Def}
    Функция $f$ называется сильно выпуклой с параметром $\mu > 0$, если для любых $x, y \in \dom f$ выполняется неравенство $f(y) \geq f(x) + \nabla f(x)^T (y-x) + \frac{\mu}{2}\|y - x\|^2$.
    \end{Def}
    
    \item \textbf{Липшицевы функции}. С такими функциями мы тоже встречались, дадим
    \begin{Def}
    Будем говорить, что $f \in C^{k, m}_{L}$, $m \leq k$, если $f \in C^k$ и для $\nabla^m f$ выполнено условие липшицевости, т.е. для любых $x, y \in \dom f$:
    $$\|\nabla^m f(y) - \nabla^m f(x)\| \leq L\|y - x\|$$
    \end{Def}
    \begin{Comment} В случае $m = 1$ под $\|\nabla^m f(y) - \nabla^m f(x)\|$ имеется в виду норма разности градиентов $\nabla f(y) - \nabla f(x)$, при $m=2$ --- норма  разности гессианов $\nabla^2 f(y) - \nabla^2 f(x)$ и т.д.
    \end{Comment}
    
    Рассмотрим частый частный случай $f \in C^{1, 1}_{L}$, когда для любых $x, y \in \dom f$ выполняется $\|\nabla f(y) - \nabla f(x)\| \leq L\|y-x\|$. Тогда можно показать, что будут выполнены следующие неравенства:
    \begin{equation*}
        \begin{cases}
        f(y) \leq f(x) + \nabla f(x)^T (y - x) + \frac{L}{2}\|y-x\|^2\\
        f(y) \geq f(x) + \nabla f(x)^T (y - x) - \frac{L}{2}\|y-x\|^2
        \end{cases}
    \end{equation*}
    а это означает, что график функции лежит между параболами с кривизнами $L$ и $-L$, касающихся графика в точке $x$ (какой бы она ни была). Липшицевость функции можно воспринимать как ограничение на скорость изменения значения функции.
    
\end{enumerate}

\subsection{Скорость сходимости итеративных процессов}
За $r_k$ обозначим величину невязки на $k$-ом шаге процесса. Определение невязки, разумеется, можно давать по-разному, вот три самых частых варианта:
\begin{align}
%\begin{gathered}
r_k &= \|f(x_k) - f(x_{\text{opt}})\| \\ 
r_k &= \|x_k - x_{\text{opt}}\| \\ 
r_k &= \|\nabla f(x_k)\|
%\end{gathered}
\end{align}

% TODO: разобраться с пробелами

Предположим сначала, что $\{r_k\}_{k=1}^{\infty}$ монотонно невозрастает. В силу того, что невязка ограничена снизу нулем, у последовательности $\{r_k\}_{k=1}^{\infty}$ существует предел. Дадим три определения.

\begin{Def}
    $\{r_k\}_{k=1}^{\infty}$ имеет $Q$-линейную скорость сходимости, если найдётся $c \in (0, 1)$ такое, что
    $$r_{k + 1} \leq cr_k \Leftrightarrow \varlimsup_{k \rightarrow \infty} \frac{r_{k+1}}{r_k} = c' \in (0, 1)$$
\end{Def}

Заметим, что справедлива цепочка $r_k \leq cr_{k-1} \leq c^2r_{k-2} \leq \dots \leq c^kr_0$. Прологарифмируем обе части и получим $\log_{10} r_k \leq k\log_{10} c + \log_{10} r_0$. Логарифм невязки может трактоваться как количество верных цифр в десятичной записи текущего решения. Выходит, для получения каждой новой верной цифры ответа необходимо совершать одинаковое число итераций.

\begin{Def}
    $\{r_k\}_{k=1}^{\infty}$ имеет $Q$-сублинейную скорость сходимости, если
    $$\varlimsup_{k \rightarrow \infty} \frac{r_{k+1}}{r_k} = 1$$
\end{Def}

Противоположно предыдущему случаю, каждая новая верная цифра ответа будет стоить всё больше и больше итераций.

\begin{Def}
    $\{r_k\}_{k=1}^{\infty}$ имеет $Q$-суперлинейную (-сверхлинейную) скорость сходимости, если
    $$\varlimsup_{k \rightarrow \infty} \frac{r_{k+1}}{r_k} = 0$$
\end{Def}

А здесь каждая новая цифра даётся легче предыдущих: всё меньше итераций требуется для того, чтобы получить новую цифру.

Теперь давайте отойдем от рассмотрения монотонных последовательностей и обратим внимание на следующий случай:
\begin{equation*}
    r_k = 
    \begin{cases}
        \frac{1}{2^k}\text{,}& k \text{ чётно,}\\
        0\text{,}& k \text{ нечётно}
    \end{cases}
\end{equation*}
Казалось бы, у этой последовательности скорость сходимости должна быть не хуже, чем у $\left\{\frac{1}{2^k}\right\}_{k=1}^{\infty}$, которая сходится линейно, однако $$\varlimsup_{k \rightarrow \infty} \frac{r_{k+1}}{r_k} = +\infty$$
Для немонотонных последовательностей дадим другие определения. Они основаны на идее, что последовательность сходится не хуже, чем мажорирующая её сверху последовательность. Сформулируем определение $R$-линейно схоядщейся последовательности, остальные даются аналогично.

\begin{Def}
    Немонотонная последовательность $\{r_k\}_{k=1}^{\infty}$ сходится $R$-линейно, если найдется такая монотонная последовательность $\{s_k\}_{k=1}^{\infty}$, $r_k \leq s_k$ для всех $k$, что $\{s_k\}_{k=1}^{\infty}$ сходится $Q$-линейно.
\end{Def}

\end{document}
