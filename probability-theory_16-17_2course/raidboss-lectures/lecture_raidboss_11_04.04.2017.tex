\section{Лекция от 04.04.2017}

\subsection{Устройство случайного графа при $np = \mathrm{const}$}

Так оказалось, что устройство компонент связности
графа сильно отличается при 
$np = c \in (0, 1), c > 1$ и $c = 1$. Известны следующие результаты:

\begin{itemize}
  \item $np = c \in (0, 1)$, тогда все компоненты размера 
  $\mathcal{O}(\ln n)$, сложных компонент нет, 
  унициклические занимают $\mathcal{O}(1)$. Все эти результаты мы
  доказали;

  \item $np = 1$, тогда все компонентны размера $\mathcal{O}(n^{\frac23})$.
  Деревья составляют почти весь граф, унициклические компоненты занимают в 
  среднем не более $\mathcal{O}(n^{\frac23})$ вершин, сложные компоненты имеют
  размер не менее $\mathcal{O}(n^{\frac23})$, а сложность ограничена 
  $\mathcal{O}_p(1)$. А также вероятность того, что есть сложная компонента 
  стремится к $\sqrt{\frac23}$. Здесь, наоборот, ни один результат мы не 
  доказывали, но каждый из них достаточно сложный;

  \item $np = c > 1$. Существует гигантская компонента размера $\Theta(n)$, все
  остальные компоненты несложные, имеют не более, чем логарифмический размер, 
  из них унициклы составляют $\mathcal{O}_p(1)$.
  Б\'{о}льшая часть лекции будет посвящена теореме о гигантской компоненте и 
  размеру компонент.
\end{itemize}

\subsection{Теорема о гигантской компоненте}

\begin{theorem}[О гигантской компоненте.]
  Пусть $np = c > 1$, где $c$ --- константа, а $\beta \in (0, 1)$ такое число, 
  что $\beta + e^{-\beta c} = 1$, тогда с вероятностью один случайный граф 
  $G(n, p)$ содержит гигантскую компоненту размера $d(n)$, где $\frac{d(n)}{n} 
  \prto \beta$, а все остальные компоненты имеют размер не более 
  $\frac{16 c}{(c - 1)^2}\ln n$.
\end{theorem}

\begin{proof}
  Пусть $v$ --- вершина случайного графа $G(n, p)$ и рассмотрим процесс набора
  компоненты, содержащей $v$. Для этого более аккуратно опишем этот процесс.

  \begin{itemize}
    \item $t$ меняется от 0 до $n$, что обозначает время;
    \item $c_t$ --- множество рассмотренных вершин на момент времени $t$;
    \item $A_t$ --- активные вершины;
    \item $u_t$ --- множество нерассмотренных вершин;
  \end{itemize}

  Изначально $c_0 = \emptyset, a_0 = \{v\}, u_0 = V \setminus \{v\}$.

  Пусть на момент времени $t$ у нас есть тройка $(c_t, A_t, u_t)$, тогда мы 
  берем $v_t \in A_t$ с наименьшим номером и меняем так нашу тройку:

  \begin{align}
    &c_{t + 1} = c_t \cup \{v_t\}\\
    &A_{t + 1} = A_t \setminus \{v_t\} \cup X_t, \text{ где $X_t$ --- соседи 
    $v_t$, принадлежащие $u_t$}\\
    &u_{t + 1} = u_t \setminus X_t.
  \end{align}

  И процесс останавливается, когда $A_t = \emptyset$ или $u_t = \emptyset$.

  Обозначим за $k_- = \frac{16c}{(c - 1)^2}\ln n$ и $k_+ = n^{\frac23}$.

  Докажем, что выполнена следующая дихотомия с вероятностью единица.

  \begin{itemize}
    \item[1.] Процесс закончился ко времени $k_-$.
    \item[2.] $\forall t \in [k_-, k_+]$ верно, что $|A_t| \geq \frac{c - 1}{2} t$.
  \end{itemize}

  Предположим, что это не так. Тогда
  заметим, что $A_i > 0$ на каком-то префиксе отрезка $[k_-, k_+]$ из-за того, 
  что процесс продолжал существовать не меньше, чем $k_-$ шагов.

  Поэтому предположим, что $\exists \ t \in [k_-, k_+]$, что 
  $|A_t| < \frac{c - 1}{2} t$ и процесс был до времени $t$.

  Тогда несложно заметить, что $|A_t| = \sum\limits_{s = 0}^{t - 1} |X_s| - t$.
  Вспомним, что $|X_0| \sim \mathrm{Bin}(n - 1, p)$, потом $|X_i| \sim 
  \mathrm{Bin}\left(n - 1 - \sum\limits_{j = 0}^{i - 1} |X_j|, p\right)$.

  Но заметим, что $n - 1 - \sum\limits_{j = 0}^{i - 1} |X_j| \geq n - 1
  - \frac{c + 1}{2}k_+$, так как $|A_t| < \frac{c - 1}{2}t$, поэтому если в 
  сумме заменить на что-то меньшее в биномиальном распределении, то получим, что
  значение только уменьшится. Пусть $Y_i \sim \mathrm{Bin}(n - 1 - 
  \frac{c + 1}{2}k_+, p)$ и независимые в совокупности.

  Тогда верна следующая цепочка:

  \begin{multline}
    \Pr{|A_t| < \frac{c - 1}{2}t} = \Pr{\sum\limits_{s = 0}^{t - 1} |X_s| <
    \frac{c + 1}{2} t} \leq \Pr{\sum\limits_{s = 0}^{t - 1} Y_s < \frac{c +
    1}{2} t} =\\= \Pr{\sum\limits_{s = 0}^{t - 1} Y_s - \E{\sum\limits_{s =
    0}^{t - 1} Y_s} < \frac{c + 1}{2}t - t\left(n - 1 - 
    \frac{c + 1}{2}k_+\right)p} 
  \end{multline}

  Воспользуемся неравенством Чернова:

  \[
  \leq  \exp\left(-\frac{\left(\frac{c + 1}{2}t
    - tp(n - 1 - \frac{c + 1}{2}k_+)\right)^2}{2tp((n - 1) - \frac{c + 1}{2}k_+
    )}\right)
  \]

  Из условия следует, что $np = c$, откуда $nk_+ \to 0$, поэтому:

  \[
    = \exp\left(-\frac{\frac{(c - 1)^2}{4} t^2 (1 + o(1))}{2tc(1 + o(1))}\right) =
    \exp\left(-\frac{\frac{(c - 1)^2}{4} t (1 + o(1))}{2c(1 + o(1))}\right)
  \]

  В данном случае воспользуемся тем, что $t \geq k_-$, поэтому верно следующее
  неравенство:

  \[
    \leq \exp\left(-\frac{(c - 1)^2}{8c}k_-(1 + o(1))\right) = 
    e^{-2\ln n (1 + o(1))} = n^{-2(1 + o(1))}
  \]

  Поэтому

  \[
    \Pr{\exists \ v \ \exists \ t \in [k_-, k_+] \implies |A_t| < \frac{c - 1}{2}t} \leq
    nk_+ n^{-2(1 + o(1))} \to 0
  \]

  Значит дихотомия выполнена.
  
  Будем называть вершину \textit{маленькой}, если для неё выполнена альтернатива
  1, иначе будем называть вершину \textit{большой}.

  Покажем, что с вероятностью один большие вершины лежат в одной компоненте.

  Пусть $v, w$ --- две большие вершины. Посмотрим для них их соответствующие
  набранные компоненты. Посмотрим на их активные вершины на шаге $k_+$, по лемме
  их не меньше, чем $\frac{c - 1}{2} k_+$. Откуда:

  \[
    \Pr{v \text{ и } w \text{ лежат в разных компонентах} \given \text{ альтернатива 2}} 
    \leq (1 - p)^{\left(\frac{c - 1}{2}k_+\right)^2} = \left(1 - \frac{c}{n}\right)^{n^{4/3}\left(\frac{c - 1}{2}\right)^2} \to 0
  \]

  В итоге получаем, что либо компонента имеет размер $\leq k_-$, либо размер
  $\geq k_+$ при этом такая компонента одна.

  Осталось показать, что больших вершин линейное количество с константой $\beta$.
  Для этого покажем, что количество маленьких вершин стремится к $(1 - \beta)n$.

  Заметим такую вещь, что $\Pr{v \text{ --- маленькая}} \leq \rho_1$, где 
  $\rho_1$ --- вероятность вырождения ветвящегося процесса с $\mathrm{Bin}(n - 1 - k_-, p)$.
  Действительно, так как в компоненте, которая набирается маленькой вершиной, не больше
  $k_-$ вершин, поэтому если брать для каждой вершины что-то поменьше в ветвящемся
  процессе, то и выродимся мы с большей вероятностью. Вспомним теорему Пуассона,
  поэтому $\rho_1 \to 1 - \beta$ (см. пример вероятности вырождения в ветвящемся
  процессе с пуассоновским законом размножения).

  Осталось оценить вероятность снизу. Оценим её таким образом (обозначим 
  <<Ветвящийся процесс>>, как <<В.п.>>):

  \begin{multline}
    \Pr{v \text{ --- маленькая}} \geq\\\geq \Pr{\text{В.п. с законом
    размножения $\mathrm{Bin}(n - 1, p)$ выродился, и всего частиц не больше $k_-$}}
  \end{multline}

  Действительно, если мы набирали вершины по такому закону и набрали вершин не больше
  $k_-$, тогда уж точно вершина $v$ маленькая.

  \begin{multline}
    \Pr{\text{В.п. с законом
    размножения $\mathrm{Bin}(n - 1, p)$ выродился, и всего частиц не больше $k_-$}} 
    =\\= \Pr{\text{В.п. с законом  $\mathrm{Bin}(n - 1, p)$ выродился}} -
    \Pr{\text{Частиц всего $> k_-$, и процесс выродился}}
  \end{multline}

  Ясно, что в разности первая вероятность стремится к $1 - \beta$ из-за той же
  теоремы Пуассона. Осталось разобраться со второй вероятностью. Надо доказать,
  что она стремится к нулю.

  Заметим, что если $Y$ --- общее число частиц в в.п. с законом $\mathrm{Pois}(c)$, тогда

  \[
    \Pr{k_- < Y < +\infty} \to 0, \text{ как остаток сходящего ряда производящей функции общего числа частиц.}
  \]

  Теперь мы получаем, что $\forall \epsilon > 0$ найдётся $k$ --- константа, что

  \[
    \Pr{k < Y < +\infty} < \epsilon
  \]

  Но мы знаем, что если $Z_n$ --- общее число частиц в $\mathrm{Bin}(n - 1, p)$,
  то $\Pr{Z_n = k} \to \Pr{Y = k}$, так как закон размножения стремится к
  пуассоновскому (можно сверху и снизу ограничить с какого-то момента 
  пуассоновскими с параметрами
  $(1 + \delta)c$ и $(1 - \delta)c$, а их производящие функции частиц удовлетворяют
  соотношению $ze^{(1\pm \delta)c(\rho(z) - 1)} = \rho(z)$, что будет 
  являться по $\delta$ непрерывной функцией из-за непрерывности неявной функции)
  и поэтому, начиная с какого-то момента:

  \[
    \Pr{k_- < Z_n < +\infty} < \Pr{k < Z_n < +\infty} < 2\epsilon
  \]

  И после этого получаем нужный предел.

  Пусть $X_n$ --- количество маленьких вершин, тогда, как мы только что выяснили:

  \[
    \E{X_n} = n(1 - \beta)(1 + o(1))
  \]

  А значит размер в среднем гигантской компоненты равен $\E{n - X_n} = n\beta(1 + o(1))$.

  Мы хотим доказать, что $\frac{n - X_n}{n} \prto \beta$ или что равносильно
  $\frac{X_n}{n} \prto 1 - \beta$. Для этого надо ограничить дисперсию и оценить 
  вторым моментом по нер-ву Чебышева. Посчитаем факториальный момент. Мы должны
  выбрать какую-то маленькую вершину, потом есть 2 варианта --- мы выбрали
  вершину из этой же компоненты и другой вариант, где мы выбрали из оставшихся не менее
  $n - k_-$ вершин. Как мы выяснили, предел при $n \to +\infty$ вероятности того,
  что вершина маленькая стремится к $(1 - \beta)$, аналогично для $n - k_-$ вершин,
  поэтому

  \[
    \E{X_n(X_n - 1)} \leq (n(1 - \beta))^2 \text{ при достаточно больших $n$.}
  \]

  Значит $\D{X_n} = \E{X_n^2} -(\E{X_n})^2 = o(n^2)$.

  \[
    \Pr{\left|\frac{X_n}{n} - (1 - \beta)\right| > \epsilon} = 
    \Pr{|X_n - n(1 - \beta)| > \epsilon n} \leq \frac{\D{X_n}}{(\epsilon n)^2} \to 0
  \]

\end{proof}

\subsection{Связность графа $G(n, p)$}

Мы только что выяснили, что при $np = c > 1$ граф содержит гигантскую компоненту.
Вопрос возникает, а когда всё же в графе существует ровно одна компонента связности.
Как мы и обещали в самом начале, докажем пороговую вероятность в $\frac{\ln n}{n}$
для свойства связности графа, а также что происходит, когда вероятность равна
$\frac{\ln n + c + o(1)}{n}$.

На самом деле получается, что всё завязано на изолированных вершинах --- если есть
изолированные вершины, то граф не связен, а если их нет (как мы позже увидим),
с вероятностью один граф уже связен.

\begin{theorem}[О распределении числа изолированных вершин.]
  Пусть $X_n$ --- число изолированных вершин в $G(n, p)$. Если
  $p = \frac{\ln n + c + o(1)}{n}, c \in \R$, тогда $X_n \dto \mathrm{Pois}(e^{-c})$.
\end{theorem}

\begin{proof}
  Воспользуемся методом моментов, а в данном случае именно будем считать факториальные
  моменты. Сначала поймём, что

  \[
    \E{X_n} = n(1 - p)^{n - 1}
  \]

  Действительно, вероятность каждой вершины быть изолированной равна $(1 - p)^{n - 1}$,
  так как не должно из неё быть проведено ни единого ребра.

  \[
    n(1 - p)^{n - 1} \sim n e^{-pn} = n e^{-\ln n - c + o(1)} \to e^{-c}
  \]

  Теперь считаем факториальный момент $r$. Мы должны выбрать $r$ различных
  вершин и не провести из первой $n - 1$ ребра, потом $n - 2$ ребра из второй
  (так как есть ребро между первой и второй вершиной) и так далее, в итоге:

  \[
    \E{X_n^{(r)}} = n(n - 1)\cdot\ldots\cdot(n - r + 1)(1 - p)^{n - 1}\cdot\ldots\cdot
    (1 - p)^{n - r}
  \]

  Но константа не влияет роли на пределы, поэтому это всё стремится к 

  \[
    (n(1 - p)^{n - 1})^r \to e^{-cr}
  \]

  Что и требовалось доказать.
\end{proof}

\begin{theorem}[Теорема о связности]
  Пусть $p = \frac{\ln n + c + o(1)}{n}$, где $c$ --- константа, тогда

  \[
    \Pr{G(n, p) \text{ связен}} \to e^{-e^{-c}}
  \]
\end{theorem}

\begin{proof}
  В силу очевидных соображений 

  \[
    \Pr{G(n, p) \text{ не связен}} \geq \Pr{G(n, p) \text{ содержит изолированные вершины}}
    \to 1 - e^{-e^{-c}}
  \]

  При таком $p$ случайный граф состоит из гигантской компоненты и компонент, размера
  не больше $a\ln n$ (дословные рассуждения как в теореме про гигантскую компоненту,
  желающие могут проверить это самостоятельно).

  Докажем, что компонент размера от $2$ до $a\ln n$ нет с вероятностью единица.

  При каждом $k$ от 2 до $a \ln n$ мы должны выбрать $k$ вершин, посмотреть,
  с какой вероятностью там образовывается хотя бы дерево (вероятность получить
  что-то сложнее дерева, меньше), а также мы должны все ребра вне не выбрать.

  \begin{multline}
    \Pr{G(n, p) \text{ содержит компоненту от 2 до $a\ln n$}}
    \leq \sum\limits_{k = 2}^{a\ln n} \binom{n}{k} k^{k - 2} p^{k - 1}(1 - p)^{k(n - k)}
    \leq\\\leq \sum\limits_{k = 2}^{a\ln n} \frac{n^k}{k!} k^{k - 2} p^{k - 1}e^{-pkn + pk^2}
  \end{multline}

  Теперь воспользуемся неравенством, что $k! > \left(\frac{k}{e}\right)^k$ и тем
  фактом, что $e^{pk^2} = o(1)$:
  \[
    = \mathcal{O}\left(n \sum\limits_{k = 2}^{a\ln n} (np)^{k - 1} \frac{1}{k^2}
    e^{k - knp}\right) =
    \mathcal{O}\left(n\sum\limits_{k = 2}^{a\ln n} \frac{1}{k^2} (npe)^{k - 1}
    e^{-k(\ln n + c + o(1))}\right)
  \]

  Далее заметим, что $np = \mathcal{O}(\ln n)$, значит $(npe)^{k - 1}
  = \mathcal{O}(e^{k\ln\ln n})$. Продолжим равенство:

  \[
    = \mathcal{O}\left(n\sum\limits_{k = 2}^{a\ln n} \frac{1}{k^2} e^{-k\ln n(1 + o(1))}\right)
  \]

  Заметим, что $e^{-k\ln n(1 + o(1))} \leq n^{-2(1 + o(1))}$, так
  как $k \geq 2$. Поэтому получаем, что

  \[
    = \mathcal{O}\left(\frac{1}{n^{1 + o(1)}}\right) \to 0
  \]


  Оценим искомую вероятность суммой трёх:

  \begin{multline}
    \Pr{G(n, p) \text{ не связен}} \leq\\\leq 
    \Pr{G(n, p) \text{ не состоит из одной гигантской компоненты и компонент $\leq a \ln n$}} +\\+
    \Pr{G(n, p) \text{ содержит компоненту от $2$ до $a\ln n$}} +\\+
    \Pr{G(n, p) \text{ состоит из одной гигантской компоненты и изол. вершин, но последние существуют}}
  \end{multline}

  Первая и вторая вероятности стремятся к нулю --- действительно, мы показывали,
  что не может быть 2 гигантских компонент и не может быть больше логарифмических компонент
  из оставшихся, вторая вероятность только что по доказанному стремится к нулю.

  Оценим третью как вероятность, что изолированные вершины существуют.
  По теореме об изолированных вершинах выходит, что

  \[
    \leq o(1) + \Pr{G(n, p) \text{ содержит изолированные вершины}} \to 1 - e^{-e^{-c}}
  \]

  Получаем, что $\Pr{G(n, p) \text{ связен}} \to e^{-e^{-c}}$.
  Что и требовалось доказать.
\end{proof}

\begin{consequence}
  Легко следствие заключается в том, что если $p = \frac{\ln n + w(n) + o(1)}{n}$,
  где $w(n) \to +\infty$, тогда граф связен с вероятностью один, если $w(n) \to -\infty$,
  тогда связен с вероятностью нуль. Предлагаем желающим проделать это легкое упражнение
  самостоятельно.
\end{consequence}

На этом случайные графы в нашем курсе заканчиваются.

