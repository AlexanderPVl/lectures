\section{Лекция от 11.04.2017}

\subsection{Мартингалы}

Исторически слово <<мартингал>> пошло
из азартных игр --- это своеобразная система управления ставками. Суть системы
заключается в удвоении ставки до выигрыша. Так, конечно, всегда гарантируется
выигрыш в одну монету, но играть нужно бесконечно долго.

В теории вероятностей мартингалом стали обозначать немного другие вещи. Интуиция такова,
что это своеобразная игра, в которой делаются ставки и по прошедшему времени
никогда невозможно определить среднее значение будущих выигрышей. Более формально
для дискретных величин мы имеем

\begin{definition}
  Последовательность случайных величин $\{X_n, n \in \N\}$ образует мартингал,
  если $\E{|X_n|} < +\infty$ и
  $\forall n \in \N, n \geq 2 \implies \E{X_n \given X_{n - 1}, \ldots, X_1} =
  X_{n - 1}$.
\end{definition}

Давайте убедимся, что $\E{X_n \given X_{k}, \ldots, X_1} = X_k \ \forall \ k
< n$, что действительно
согласуется с интуицией --- по первым $k$ результатам невозможно предугадать
следующие.

По телескопическому свойству и определению имеем:

\[
  \E{X_n \given X_k, \ldots, X_1} = \E{\E{X_n \given X_{n - 1}, \ldots, X_1} \given
  X_k, \ldots, X_1} = \E{X_{n - 1} \given X_k, \ldots, X_1} = \ldots = X_k.
\]

Но как говорится, нам опять этого мало. Мартингалы можно определить для 
континуума случайных величин!

\begin{definition}
  Пусть $\{X_t, t \geq 0\}$ --- случайные величины, где $t \in T$, тогда эти случайные
  величины образуют мартингал, если

  \[
    \E{X_t \given X_s, s \leq u} = X_u, \text{ где $t > u \geq 0$}.
  \]
\end{definition}

Возникает естественный вопрос --- а как понимать то, что написано в условном
матожидании? Что значит условное матожидание по счётному множеству (или даже континууму)
случайных величин. Для этого нам придётся расширить знания про вероятностные 
меры и условное математическое ожидание.

\begin{definition}
  Пусть $\xi$ --- случайная величина на $(\Omega, \F, \Pr)$. Тогда индикаторные события
  $\{\{\xi \in B\}, B \in \F\} = \F_\xi$ тоже образуют сигма алгебру из-за свойств
  сигмы алгебры $\F$. Такая сигма алгебра называется \textit{порожденной}
  случайной величиной
  $\xi$. Для вектора понятие вводится аналогично.
\end{definition}

\begin{definition}
  Пусть $\eta$ --- случайная величина, а $\mathscr{C} \subset \F$ --- подсигма
  алгебра событий в $\F$. Тогда $\eta$ является \textit{$\mathscr{C}$ измеримой},
  если $\F_\eta \subset \mathscr{C}$.
\end{definition}

А следующую лемму мы оставим без доказательства.

\begin{lemma}
  Если $\eta$ измерима относительно $\F_\xi$, тогда существует борелевская
  функция $f$, что $\xi \overset{\text{п.н.}}{=} f(\eta)$.
\end{lemma}

Теперь наконец-то поймём, что значит условное математическое ожидание в
общем случае.

\begin{definition}
  Условным математическим ожиданием случайной величины $\xi$ относительно
  подсигма алгебры $\mathscr{C} \subset \F$ называют $\E{\xi \given \mathscr{C}}$ ---
  $\mathscr{C}$ измеримой величиной, а также $\forall A \in \mathscr{C} \implies
  \E{\xi\I\{\xi \in A\}} = \E{\E{\xi \given \mathscr{C}} \I\{\xi \in A\}}$.
\end{definition}

Заметим, что при $\mathscr{C} = \F_\eta$ определение в точности совпадает с определением
с лекции основного курса. Все свойства условного математического ожидания сохраняются и доказываются
аналогично.

\subsection{Марковские моменты}

На данный момент наша мотивация состоит в том, чтобы изучать случайные процессы.
В них нам интересны какие-то моменты времени при которых начинают
происходить интересные вещи (разорение игрока, неограниченный рост и т.д.). Для
того, чтобы это изучать легче, введем несколько определений.

Для начала нам понадобится понятие фильтрации.

\begin{definition}
  Пусть есть вероятностное пространство $(\Omega, \F, \Pr)$. Тогда набор
  сигма алгебр $\mathbb{F} = \{\F_t, t \in T \subset \R\}$ называется фильтрацией,
  если $\forall t, s \in T, s \leq t$ следует, что $\F_s \subset \F_t \subset \F$.
\end{definition}

Фильтрацию можно неформально понимать, как набор информации, которая накапливается
со временем, её становится всё больше и больше.

\begin{definition}
  Пусть $\{X_t, t \in T\}$ --- случайный процесс. Для любого $t \in T$ определим

  \[
    \F_t^x = \sigma(X_s, s \leq t).
  \]

  То есть это минимальная сигма алгебра на всех $X_s$ при  $s \leq t$. Тогда
  фильтрация $\mathbb{F}^x$ называется естественной фильтрацией.
\end{definition}

Введем понятие согласованности случайного процесса с фильтрацией $\mathbb{F}$.

\begin{definition}
  Процесс $\{X_t, t \in T\}$ согласован с фильтрацией $\mathbb{F}$, если
  $\forall t \in T$ величина $X_t$ измерима относительно $\F_t$.
\end{definition}

Теперь мы готовы определить понятие марковского момента. Марковский момент
не возникает сам по себе, он возникает относительно фильтрации.

\begin{definition}
  Пусть есть фильтрация $\mathbb{F} = \{\F_t, t \in T\}$ на $(\Omega, \F, \Pr)$.
  Тогда случайная величина $\tau : \Omega \to T \cup \{+\infty\}$ называется марковским моментом
  относительно фильтрации $\mathbb{F}$, если
  \[
    \{\tau \leq t\} \in \F_t \ \forall t \in T
  \]
\end{definition}

Поясним это формальное определение. Представим, что у нас есть какой-то случайный
процесс относительно естественной фильтрации. Тогда марковский момент означает,
что при фиксированном $t$ мы можем однозначно сказать, наступил ли момент $\tau$
или нет.

Приведем хороший пример того, что является марковским моментом:

\begin{example}
  Пусть есть процесс $\{X_n, n \in \N\}$ и время дискретно. Для любого множества
  $B \in \B(\R)$ введем такое $\tau_B = \min\{n : X_n \in B\}$ --- первый момент
  попадания в множество. Тогда утверждается, что $\tau_B$ --- марковский момент
  относительно $\mathbb{F}^x$ --- естественной 
  фильтрации $X$.

  Давайте поймём, почему это правда. Неформально, мы смотрим, попал ли до момента
  $n$ процесс в само множество и отвечаем, наступил ли данный момент $\tau_B$.

  \[
    \{\tau_B \leq n\} = \bigcup\limits_{k = 1}^n \{X_k \in B\} \in \F_n^x
  \]

  Последнее включение верно, так как каждое $\{X_k \in B\} \in \F_k^x$ из-за
  естественной фильтрации, но мы знаем, что $\F_k^x \subset \F_n^x$, а значит
  и всё объединение там лежит.
\end{example}

\begin{definition}
  Если марковский момент $\tau$ относительно фильтрации $\mathbb{F}$ такой, что
  $\Pr{\tau < +\infty} = 1$, то $\tau$ называют моментом остановки.
\end{definition}

Приведем несколько примеров, которые у нас уже рассматривались без определения
марковского момента.

\begin{itemize}
  \item $\{S_n, n \in \Z_+\}$ --- простое симметричное случайное блуждание. 
  $\tau_a = \min\{n : S_n = a\}$ --- момент остановки, так как у нас в арсенале
  есть закон повторного логарифма, который утверждает, что мы когда-нибудь
  все точки достигнем;
  \item Несимметричное случайное блуждание $\{S_n, n \in \Z_+\}, p > q$ и
  $\tau_a = \min\{n : S_n = a\}$. Предлагается самостоятельно доказать, что
  при $a \geq 0$ следует, что $\tau_a$ --- момент остановки относительно
  естественной фильтрации $\mathbb{F}^x$. При $a < 0$ --- $\tau_a$ просто марковский
  момент.
\end{itemize}

\subsection{Мартингалы. Продолжение}

Теперь мы готовы ввести общее понятие мартингала.

\begin{definition}
  Процесс $\{X_t, t \in T\}$ называется мартингалом относительно фильтрации $\mathbb{F} =
  \{\F_t, t \in T\}$, если

  \begin{enumerate}
    \item $X_t$ согласована с $\mathbb{F} \ \forall t \in T$;
    \item $\E{|X_t|} < +\infty \ \forall t \in T$;
    \item $\E{X_t \given \F_s} = X_s \ \forall s, t \in T, s \leq t$.
  \end{enumerate}
\end{definition}

\begin{definition}
  Если свойство 3 у мартингалов такое, что $\E{X_t \given \F_s} \geq X_s$, тогда
  процесс называют субмартингалом, а если $\E{X_t \given \F_s} \leq X_s$, тогда
  процесс называют супермартингалом.
\end{definition}

Давайте приведем какие-нибудь примеры мартингалов.

\begin{example}
  Пусть $S_n$ --- сумма независимых случайных величин, и мы хотим понять, когда
  $\{S_n, n \in \Z_+\}$ является мартингалом относительно естественной фильтрации.

  \[
    \E{S_n \given S_{n - 1}, \ldots, S_1} = \E{S_{n - 1} + \xi_n \given
    S_{n - 1}, \ldots, S_1} = S_{n - 1} + \E{\xi_n}
  \]

  И это равно $S_{n - 1}$ тогда и только тогда, когда $\E{\xi_n} = 0$.
\end{example}

\subsection{Теорема об остановке}

Теперь сформулируем одну из важных теорем. А именно теорему об остановке мартингала.
Ясно, что в фиксированные моменты времени средние значения величин процесса совпадают
(просто по определению), но теорема утверждает, что в любой случайный 
ограниченный марковский момент времени средние величины равны. Формально, она формулируется так.

\begin{theorem}[Об остановке]
  Пусть процесс $\{X_n, n \in \Z_+\}$ согласован с фильтрацией $\mathbb{F}$. Тогда
  $X_n$ --- мартингал (субмартингал) $\iff$ если $\forall \tau, \sigma$ --- ограниченные
  марковские моменты относительно фильтрации $\mathbb{F}$ с условием $\tau \leq \sigma$
  с вероятностью 1, то выполняется равенство $\E{X_\tau} = (\leq) \E{X_\sigma}$.
\end{theorem}

Перед доказательством сделаем одно замечание. У нас был пример, в
симметричном случайном
блуждании, где $\tau_1 = \min\{n : S_n = 1\}$ и $\tau_2 = \min\{n : S_n = 2\}$.
Ясно, что $\tau_1 \leq \tau_2$, так как если уж наступил момент времени, где
$S_n = 2$, то до этого был момент времени, где $S_n = 1$.
Этот пример лишь показывает, что от условия ограниченности никуда не деться, иначе
теорема неверна.

\begin{proof}
  Докажем сначала теорему в прямую сторону. Пусть $X$ --- мартингал (субмартингал).
  Пусть есть какие-то $\tau$ и $\sigma$ --- ограниченные марковские моменты (натуральным
  числом $m$).

  $\forall \ell < m$ рассмотрим математическое ожидание $\E{X_\tau \I\{\tau = \ell\}}$.
  Из-за того, что в данном случае $\tau = \ell$, тогда можно заменить $X_\tau$ на
  $X_\ell$, то есть  $\E{X_\tau \I\{\tau = \ell\}} = \E{X_\ell \I\{\tau = \ell\}}$.

  Мы знаем, что если $\tau = \ell$, то $\sigma \geq \ell$ с вероятностью один, поэтому

  \[
    \E{X_\ell  \I\{\tau = \ell\}} = \E{X_\ell  \I\{\tau = \ell, \sigma \geq \ell\}}
  \]

  Давайте теперь последнее матожидание разобьём на два --- когда $\sigma = \ell$
  и когда $\sigma \geq \ell + 1$, то есть

  \[
    \E{X_\ell  \I\{\tau = \ell, \sigma \geq \ell\}} = 
    \E{X_\ell  \I\{\tau = \ell, \sigma = \ell\}} + \E{X_\ell  \I\{\tau = \ell, \sigma \geq \ell + 1\}}
  \]

  После этого воспользуемся определением мартингала (субмартингала) для 
  второго слагаемого. Получаем:

  \begin{multline}
    \E{X_\ell  \I\{\tau = \ell, \sigma = \ell\}} + \E{X_\ell  \I\{\tau = \ell, \sigma \geq \ell + 1\}}
    = (\leq)\\= (\leq) \E{X_\ell  \I\{\tau = \ell, \sigma = \ell\}}  +
    \E{\E{X_{\ell + 1} \given \F_\ell} \I\{\tau = \ell, \sigma \geq \ell + 1\}}
  \end{multline}

  Заметим, что $\{\tau = \ell, \sigma \geq \ell + 1\} = \{\tau = \ell\} \cap
  \overline{\{\sigma \leq \ell\}} \in \F_\ell$, то есть эта величина измерима
  относительно $\F_\ell$, откуда мы можем внести под условное математическое
  ожидание.

  \begin{multline}
    = (\leq) \E{X_\ell  \I\{\tau = \ell, \sigma = \ell\}}  +
    \E{\E{X_{\ell + 1} \I\{\tau = \ell, \sigma \geq \ell + 1\} \given \F_\ell}}
    =\\= \E{X_\ell  \I\{\tau = \ell, \sigma = \ell\}} + \E{X_{\ell + 1}  \I\{\tau = \ell, \sigma \geq \ell + 1\}}
    =\\= \sum\limits_{k = \ell}^{\ell + 1}\E{X_k  \I\{\tau = \ell, \sigma = k\}}
    + \E{X_{\ell + 1}  \I\{\tau = \ell, \sigma \geq \ell + 2\}}
  \end{multline}

  Продолжаем так делать до момента времени $m$. Последнее матожидание занулится,
  так как $\{\sigma \geq m + 1\}$ никогда не происходит, поэтому получаем:

  \[
    = \sum\limits_{k = \ell}^m \E{X_k \I\{\tau = \ell, \sigma = k\}}
  \]

  Теперь мы можем $X_k$ заменить на $X_\sigma$, так как $\sigma = k$, откуда

  \[
    = \sum\limits_{k = \ell}^m \E{X_\sigma \I\{\tau = \ell, \sigma = k\}} =
    \E{X_\sigma \I\{\tau = \ell, \sigma \geq \ell\}} = \E{X_\sigma \I\{\tau = \ell\}}.
  \]

  Последнее равенство следует из равенства событий при индикаторах, потому что суть
  $\sigma \geq \tau = \ell$ с вероятностью один.

  В итоге мы получили, что $\E{X_\tau \I\{\tau = \ell\}} = (\leq) \E{X_\sigma \I\{\tau = \ell\}}$,
  суммируя по всем $\ell$ получим требуемое.

  Теперь в обратную сторону. Предположим, что $k < n$, нам надо доказать, что
  условное математическое ожидание $\E{X_n \given \F_k} = (\geq) X_k$.

  Зафиксируем $A \in \F_k$. Рассмотрим следующее отображение:

  \[
    \tau_A(\omega) =
    \begin{cases}
      k, \omega \in A\\
      n, \omega \not\in A
    \end{cases}
  \]

  Покажем, что $\tau_A$ --- марковский момент относительно фильтрации $\mathbb{F}$.

  \[
  \{\tau_A \leq t\}=
    \begin{cases}
      \emptyset \in \F_t, \text{ если } t < k \\
      A \in \F_k \subset \F_t, \text{ если } k \leq t < n\\
      \Omega \in \F_t
    \end{cases}
  \]

  Более того, этот марковский момент ещё и ограничен. Положим $\sigma = n$ 
  (тривиально, что $\sigma \geq \tau_A$), тогда
  по условию $\E{X_{\tau_A}} = (\leq) \E{X_n}$.

  Но что такое математическое ожидание $X_{\tau_A}$? Оно принимает всего два значения
  --- $k$ и $n$. Значит это равно:

  \[
    \E{X_{\tau_A}} = \E{X_k \I\{\omega \in A\}} + \E{X_n \I\{\omega \in \overline{A}\}}
  \]

  $X_n$ мы тоже можем так представить:

  \[
    \E{X_n} = \E{X_n \I\{\omega \in A\}} + \E{X_n \I\{\omega \in \overline{A}\}}
  \]

  Для всех $A \in \F_k$ мы получаем равенство в случае мартингала
  (и неравенство в случае субмартингала) $\E{X_k \mathbf{I}_A} = (\leq) 
  \E{X_n \mathbf{I}_A}$. В силу интегрального свойства

  \[
    \E{X_k \mathbf{I}_A} = (\leq) \E{X_n \mathbf{I}_A} = (\leq)
    \E{\E{X_n \given \F_k} \mathbf{I}_A}
  \]

  Так как обе величины $X_k$ и $\E{X_n \given \F_k}$ являются $\F_k$ измеримыми,
  получаем, что в случае равенства они равны до п.н., в случае неравенства, выполняется
  неравенство с точностью по п.н.

  Тем самым теорема об остановке полностью доказана.
\end{proof}

Покажем одно хорошее следствие из теоремы об остановке.

\begin{lemma}
  Пусть $\{X_n, n \in \Z_+\}$ --- мартингал относительно $\mathbb{F} = \{\F_n, n \in \Z_+\}$.
  Пусть $\tau$ --- момент остановки относительно $\mathbb{F}$, причем
  $\exists C > 0 \ \forall n \in \N \implies |X_{\min(\tau, n)}| \leq C$, то
  $\E{X_{\tau}} = \E{X_0}$.
\end{lemma}

Пусть мы придумали какую-то хорошую стратегию для карточной игры, останавливаясь
в момент $\tau$, который является моментом остановки, то есть мы следим что происходит
на каждом шаге, выигрываем или проигрываем и строим исходя из этого нашу стратегию.
Если мы её разработали, то наш выигрыш будет (по лемме) ничуть не отличаться
в среднем от того, что мы имели в начале. То есть если мы играем в игру с нулевой
суммой (выигрываем и проигрываем одинаковое количество денег), то никакая разумная
стратегия не приведет нас к успеху.

\begin{proof}
  Пусть $\tau_n = \min(\tau, n)$ --- тоже марковский момент относительно
  той же фильтрации $\mathbb{F}$, притом он ограничен. Тогда к $\tau_n$ применима
  теорема об остановке: $\E{X_{\tau_n}} = \E{X_0}$. Заметим такую вещь, что
  $X_{\tau_n} \asto X_{\tau}$. Это действительно очевидно, так как $\tau$ --- 
  момент остановки, а $\tau_n$ просто будет тогда поточечно сходиться в $\tau$.

  Но мы ещё знаем, что $|X_{\tau_n}| \leq C$ (дано по условию). Значит можно
  применить теорему Лебега. 

  \[
    \E{X_0} = \lim\limits_{n \to +\infty} \E{X_{\tau_n}} = \E{X_{\tau}}
  \]
\end{proof}

\subsection{Задача о разорении игрока}

Применим теорему об остановке в данной задаче. Опишем задачу.

У нас есть игрок, он пришёл в казино и хочет выиграть денег. В начале у него
есть $x \in \N$ условных единиц --- начальный капитал. Деньги, которые у него есть
и которыми он может распоряжаться. На каждом шаге он ставит одну единицу денег,
выигрывает с вероятностью $p$, проигрывает с вероятностью $q = 1 - p$. Если
он достиг какого-то уровня $b \geq x$, то он успокаивается и уходит из казино.
Другой вариант, что игрок играл и его деньги уменьшились до какого-то $a \leq x$.
Если он достиг этого уровня, то он уходит из казино.

Рассмотрим математическую модель нашей игры. Раз мы сдвигаемся на единицу всё время,
имея в начале $x$, то получаем <<сдвинутое>> случайное блуждание.

Пусть $\{\xi_n, n \in \N\}$ --- независимые одинаково распределенные
случайные величины, причем $\Pr{\xi_n = 1} = p, \Pr{\xi_n = 0} = 1 - p = q$.

Рассмотрим такой процесс $S_n = x + \xi_1 + \ldots + \xi_n, n \in \Z_+$.

Обозначим $\tau = \min(n : S_n = a \text{ или } S_n = b)$ --- момент окончания
игры.

Вопрос, который нас интересует --- это значение $\Pr{S_\tau = a}$, то есть с какой
вероятностью мы разоримся.

Убедимся, что $\tau$ является моментом остановки относительно естественной фильтрации
$\{S_n, n \in \Z_+\}$. 

Ясно, что $\tau$ --- марковский момент, так как первое попадание в какое-то множество
всегда является марковским моментом относительно естественной фильтрации $\mathbb{F}^S$.
Также понятно, что это момент остановки, так как если $p \neq q$, то мы сдвигаемся
в какую-то сторону, а если $p = q$, то у нас есть закон повторного логарифма,
который гласит, что мы принимаем сколь угодно большие значения с вероятностью 1.

Рассмотрим несколько случаев.

\begin{itemize}
  \item $p = q = \frac12$. Тогда $\{S_n, n \in \Z_+\}$ --- мартингал, так как
  это процесс приращения с нулевым средним (см. пример в начале лекции).
  Заметим, что $|S_{\min(\tau, n)}| \leq \max(|a|, |b|)$, так как наши деньги
  всегда лежат на отрезке, пока мы не достигли уровня $\tau$. Откуда по следствию
  мы получаем, что

  \[
    \E{S_\tau} = x
  \]

  Но $\E{S_\tau} = a\Pr{S_\tau = a} + b\Pr{S_\tau = b} \implies \frac{b - x}{b 
  - a} = \Pr{S_\tau = a}$.

  \item $p \neq q \in (0, 1)$ (граничные случаи неинтересны, там $\tau$ просто
  равна константе). Обозначим $\alpha = \frac{q}{p}$.

  Введем $Y_n = \alpha^{S_n}$. Легко понять, что $\E{\alpha^{\xi_i}} =
  \alpha p + \frac{1}{\alpha}(1 - p) = 1$, значит $\{Y_n, n \in \Z_+\}$
  --- мартингал относительно естественной фильтрации $\mathbb{F}^S$ (можно честно
  выписать условное матожидание). Заметим, что

  \[
    Y_{\min(\tau, n)} \leq \max\left(\left(\frac{q}{p}\right)^a, \left(\frac{q}{p}\right)^b\right)
  \]

  Поэтому по следствию $\E{Y_{\tau}} = \E{Y_0} = \left(\frac{q}{p}\right)^x$, откуда

  \[
    \Pr{S_{\tau} = a} = \frac{\left(\frac{q}{p}\right)^b - 
    \left(\frac{q}{p}\right)^x}{\left(\frac{q}{p}\right)^b - \left(\frac{q}{p}\right)^a}
  \]
\end{itemize}
