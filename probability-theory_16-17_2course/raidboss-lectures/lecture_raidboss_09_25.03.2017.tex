\section{Лекция от 25.03.2017}

\subsection{Число копий в строго сбалансированных графах}

\begin{proof}[Продолжение доказательства теоремы 18.]
  Напомним, что мы хотим доказать, что  $\mathsf{E''}_k$ стремится к нулю.

  Это сделать нам поможет следующая лемма:

  \begin{lemma}
    Пусть $q(t)$ --- минимальное число рёбер в объединении $k$ копий графа $G$,
    что общее число вершин этих копий в точности равно $t$ (другими словами,
    $v(G_{i_1} \cup \ldots \cup G_{i_k}) = t$). Тогда если $t < k v(G)$ (что
    логично, так как хотя бы одна вершина у копий должна совпадать),
    то $q(t) > t m(G)$.
  \end{lemma}

  \begin{proof}
    Введем функцию $f(H) \ \forall H \subseteq G$ такую, что $f(H) = m(G)v(H) - e(H)$.

    Заметим, что $f(G) = 0$ и $f(H) > 0
    \ \forall \varnothing \subset H \varsubsetneq G$ из-за строгой сбалансированности графа.

    Также $f(H_1 \cup H_2) = f(H_1) + f(H_2) - f(H_1 \cap H_2)$, так как $m(G)$
    это какая-то константа, а функция числа вершин и ребер удовлетворяют этому 
    соотношению.

    Обозначим $v = v(G)$ для краткости.

    Если переформулировать лемму на языке функции $f$, то надо доказать, что
    \[
    f(G_{i_1} \cup \ldots \cup G_{i_k}) < 0
    \]

    при условии, что 
    $v(G_{i_1} \cup \ldots \cup G_{i_k}) < kv$. Будем делать это по индукции.

    Начнём с $k = 2$. Из-за того, что $G_{i_1}$ и $G_{i_2}$ имеют хотя бы одну
    общую вершину и не совпадают,
    то их пересечение $H \cong G_{i_1} \cap G_{i_2}$ является
    собственным подграфом графа $G$. Ясно, что $f(G_{i_1}) = f(G_{i_2}) = 0$, откуда

    \[
      f(G_{i_1} \cup G_{i_2}) = f(G_{i_1}) + f(G_{i_2}) - f(G_{i_1} \cap G_{i_2})=
      -f(H) < 0
    \]

    Шаг индукции от всех меньших $k$ к $k$.

    Без ограничения общности будем считать, что 
    $v(G_{i_1} \cup \ldots \cup G_{i_{k - 1}}) < (k - 1)v$, так как всё объединение
    имеет меньше $kv$ вершин, а значит и какое-то объединение из $k - 1$ копии
    имеет общую вершину.

    Обозначим за $H_k = G_{i_k} \cap (G_{i_1} \cup \ldots \cup G_{i_{k - 1}})$.
    Это какой-то подграф графа $G$, а значит $f(H_k) \geq 0$, откуда

    \[
      f(G_{i_1} \cup \ldots \cup G_{i_{k}}) = f(G_{i_k}) + f(G_{i_1} \cup \ldots \cup G_{i_{k - 1}})
      - f(H_k) = f(G_{i_1} \cup \ldots \cup G_{i_{k - 1}}) - f(H_k) < 0
    \]

    По предположению индукции первое слагаемое отрицательное и мы ещё вычитаем
    что-то неотрицательное, откуда верно последнее неравенство.
  \end{proof}

  Давайте оценивать $\mathsf{E''}_k$.

  \[
    \mathsf{E''}_k = \sum\limits_{\substack{i_1, \ldots, i_k,\\v(G_{i_1} \cup \ldots \cup G_{i_k}) < kv}}
    \E{\mathbf{I}_{i_1} \ldots \mathbf{I}_{i_k}} = \sum\limits_{t = v}^{kv - 1}
    \sum\limits_{\substack{i_1, \ldots, i_k,\\v(G_{i_1} \cup \ldots \cup G_{i_k}) = t}}
    p^{e(G_{i_1} \cup \ldots \cup G_{i_k})}
  \]

  Тут давайте остановимся на секунду. Во-первых, ограничения суммирования выбраны
  правильно, так как копии могут быть расположены как-то хитрым образом, что 
  может дать любое количество вершин от $v$ до $kv - 1$.

  Заменим показатель при $p$ на $q(t)$ и напишем знак <<$\leq$>>, так как $q(t)$
  --- минимальное количество ребер в объединении, если образовалось $t$ вершин.

  Осталось разобраться с количеством таких
  графов. Их не больше, чем $\mathcal{O}(n^t)$, так как надо выбрать $t$ вершин
  из $n$ и как-то их упорядочить, после этого уложить туда $k$ копий графа $G$.
  Последнее укладывание посчитаем какое-то константное количество (так как $k, v$
  фиксированны у нас):

  \begin{multline}
    \sum\limits_{t = v}^{kv - 1}
    \sum\limits_{\substack{i_1, \ldots, i_k,\\v(G_{i_1} \cup \ldots \cup G_{i_k}) = t}}
    p^{e(G_{i_1} \cup \ldots \cup G_{i_k})} \leq 
    \sum\limits_{t = v}^{kv - 1} p^{q(t)} \mathcal{O}(n^t) =
    \sum\limits_{t = v}^{kv - 1} p^{q(t) - t\cdot m(G)} \mathcal{O}\left(\left(np^{m(G)}\right)^t\right) \to\\\to
    \sum\limits_{t = v}^{kv - 1} 0 \cdot \mathcal{O}(c^t) \to 0
  \end{multline}

  Выше мы воспользовались тем, что $p \to 0$ и $q(t) - tm(G) > 0$, то есть, что
  нам даст стремление каждого слагаемого к нулю с ростом $n$. А в 
  $\mathcal{O}$-большом останется как раз константа в какой-то фиксированной
  степени, что завершает наше доказательство.
\end{proof}


\subsection{Число копий объединения строго сбалансированных графов}

Только что мы разобрались с одной копией строго сбалансированных графов. И оказывается,
что если брать непересекающиеся копии с одинаковой плотностью, то результат известен.

Доказывать этот результат мы не будем, но доказательство будет похожим. Расскажем
о нескольких теоретических фактах, которые могут эту теорему доказать (и просто
полезно о них знать).

\begin{definition}
  Пусть $X = (X_1, \ldots, X_n)$~--- случайный вектор и $\alpha \in \Z_+^n$ ---
  мультииндекс, тогда \textit{моментом} $\alpha$ случайного вектора называется 
  $\E{X^\alpha} = \E{X_1^{\alpha_1}\cdot\ldots\cdot X_n^{\alpha_n}}$.
\end{definition}

\begin{definition}
  Распределение вектора $X$ однозначно определяется своими моментами, если из того,
  что $\E{X^\alpha} = \E{Y^\alpha}, \ \forall \alpha \in \Z_+^n$ следует, что $X \eqdist Y$.
\end{definition}

\begin{lemma}[Многомерный метод моментов]
  Пусть $X$ однозначно определяется своими моментами. Тогда если 
  $\E{X_n^\alpha} \to \E{X^\alpha} \ \forall \alpha \in \Z_+^n$, то $X_n \dto X$.
\end{lemma}

\begin{theorem}
  Пусть $G_1, \ldots,G_s$ различные строго сбалансированные графы с одинаковой
  плотностью $\rho(G_1) = \ldots = \rho(G_s)$.
  Пусть $X(G_i)$ --- число копий $G_i$ в $G(n, p)$, а также
  $np^{\rho(G_1)} \to c$, тогда
  $X(G_1)\ldots X(G_s) \dto Z_1\ldots Z_s$, где $Z_i \sim 
  \mathrm{Pois}\left(\frac{c^{v(G_i)}}{\mathrm{aut}(G)}\right)$ и $Z_i$ независимы
  в совокупности.
\end{theorem}

\begin{proof}
  Без доказательства.
\end{proof}

\begin{example}
  Приведем некоторые примеры, иллюстрирующую данную теорему.

  \begin{itemize}
    \item $G = C_3 \sqcup C_4$, где $C_i$ --- цикл длины $i$.
    Тогда $X(G) \dto Z_1Z_2$, где $Z_i \sim
    \mathrm{Pois}\left(\frac{c^{i + 2}}{2(i + 2)}\right)$.
    То есть в данном случае будет, что $\Pr{X(G) = 0} = 
    1 - \left(1 - e^{-\frac{c^3}{6}}\right)\left(1 - e^{-\frac{c^4}{8}}\right)$;
    \item $G = C_3 \sqcup C_3$. Здесь, конечно, неприменима данная теорема,
    но забегая вперед (а именно с этим будет связана одна из задач домашнего
    задания) $X(G) \dto \frac{Z(Z - 1)}{2}$, где $Z \sim 
    \mathrm{Pois}\left(\frac{c^{3}}{6}\right)$. Фактически мы выбираем один треугольник
    из пуассоновского распределения, потом другой и не считаем повторы;
    \item Треугольник с одним выходящим ребром из одной вершины. Аналогично забегая
    вперед проведем неформальные рассуждения.

    Как мы знаем, из одной вершины выходит $\mathrm{Bin}(n - 1, p)$ ребер, что
    при $n \to +\infty$ стремится к $\mathrm{Pois}(c)$, если $np \to c$ (как
    раз плотность у треугольника равна единице). Значит из трёх вершин выходит
    $\mathrm{Pois}(3c)$ вершин (так как сумма пуассоновских --- пуассоновское
    распределение). Тогда здесь будет следующий результат (предлагается разобраться
    с этим в домашнем задании):

    \[
      X(G) \dto \sum\limits_{i = 1}^{Z} W_i
    \]

    Где $Z \sim \mathrm{Pois}\left(\frac{c^3}{6}\right)$, а $W_i$ независимы и
    $W_i \sim \mathrm{Pois}(3c)$, а также $Z$ независима с $W_i$.

    Откуда получаем, что

    \[
      \Pr{X(G) = 0} \to \sum\limits_{k = 0}^{\infty} \Pr{Z = k}e^{-3ck} = 
      \sum\limits_{k = 0}^{\infty} \frac{\left(\frac{c^{3}}{6}\right)^k}{k!}e^{\frac{-c^3}{6}}e^{-3ck} =
      e^{-\frac{c^3}{6}(1 - e^{-3c})}
    \]

    Получаем такой парадокс. Граф устроен очень просто, а вероятность того, что
    копии нет, имеет уже двойную экспоненту.
  \end{itemize}
\end{example}

Для случайного графа так же верна центральная предельная теорема. Оставим её,
как обычно, без доказательства.

\begin{theorem}[ЦПТ для случайного графа]
  Пусть $G$ произвольный граф, а $X(G)$ число копий в $G(n, p)$. Если 
  $np^{m(G)}\to +\infty$ и $n^2(1 - p) \to +\infty$ (это условие говорит, что
  $p$ не слишком близко к единице), тогда

  \[
    \frac{X(G) - \E{X(G)}}{\sqrt{\D{X(G)}}} \dto \mathcal{N}(0, 1)
  \]
\end{theorem}

\subsection{Эволюция случайного графа}

От количества фиксированных графов перейдём к более общим структурам случайного
графа --- компонентам связности, циклам и прочим вещам. В данном теме существует
принципиально четыре различных случая:

\begin{itemize}
  \item $np \to 0$;
  \item $np \to c, c \in (0, 1)$;
  \item $np \to 1$;
  \item $np \to c, c \in (1, +\infty]$.
\end{itemize}

Докажем несколько лемм, которые дадут понимание, как устроены компоненты связности.

\begin{lemma}
  Если $np \to 0$, тогда $\Pr{G(n, p) \text{ содержит циклы}} \to 0$.
\end{lemma}

\begin{proof}
  Заметим, что то, что мы доказывали в главе про количество копий нам не подходит,
  потому что там мы фиксировали конкретный граф, а в конкретном случае циклы могут зависеть
  от $n$.

  Пусть $X_n$ --- число циклов в случайном графе $G(n, p)$. Тогда воспользуемся
  методом первого момента и докажем, что математическое ожидание стремится к нулю,
  тогда докажем, что и вероятность стремится к нулю.

  \[
    \E{X_n} = \sum\limits_{k = 3}^n \binom{n}{k}\frac{k!}{2k}p^k
  \]

  Действительно, наименьшая длина цикла равна трём, мы должны выбрать упорядоченных
  $k$ вершин и разделить на количество автоморфизмов.

  \[
     \leq \sum\limits_{k = 3}^n \frac{n^k}{k!}\frac{k!}{2k}p^k = 
     \sum\limits_{k = 3}^n \frac{(np)^k}{2k} \leq \sum\limits_{k = 3}^n (np)^k
     = \frac{(np)^3}{1 - np} = \mathcal{O}((np)^3) \to 0
  \]
\end{proof}

То есть в данном случае все компоненты деревья. Об их размерах судить сложно,
это зависит от стремления к нулю.

\begin{lemma}
  Пусть $np \to c, c \in (0, 1)$, тогда с вероятностью, стремящейся к единице
  в $G(n, p)$ нет компонент размера больше, чем $\frac{3}{(1 - c)^2}\ln n$.
\end{lemma}

\begin{proof}
  Пусть $k_0 = \left\lfloor \frac{3}{(1 - c)^2} \ln n \right\rfloor$.

  Рассмотрим произвольную вершину $v$. Будем делать аналог обхода в ширину,
  сначала присоединим к ней сколько-то вершин (точнее, выберем ребра из этой вершины),
  после этого из каждой вершины добавим ещё не добавленные вершины и так далее.

  Пусть $X_i$ --- число вершин, присоединенных к вершине $i$.

  \[
    \Pr{\text{Компонентна содержит вершин} > k_0} = \Pr{\sum\limits_{i = 1}^{k_0} X_i \geq k_0}
  \]

  А если за $k_0$ добавлений (с какого-то
  момента может быть и нулевое добавление) мы добавили хотя бы $k_0$ вершин,
  тогда мы получили компоненту, строго большей размерности (так как есть
  ещё вершина $v$).

  Каждое $X_i$ это какое-то биномиальное условное распределение, так как нам
  запрещено брать, что было на предыдущих уровнях. Тогда если мы заменим все
  $X_i$ на независимые $Y_i \sim \mathrm{Bin}(n - 1, p)$, то мы только увеличим вероятность,
  так как мы посчитаем какие-то вершины много раз.

  \[
    \leq \Pr{\sum\limits_{i = 1}^{k_0} Y_i \geq k_0}
  \]

  Так как сумма биномиальных с одним и тем же параметром $p$ --- биномиальное,
  то получаем, что

  \[
    = \Pr{Z \geq k_0}, \text{ где } Z \sim \mathrm{Bin}((n - 1)k_0, p)
  \]

  А теперь воспользуемся неравенством Чернова и тем, что $1 - c > 0$ (это важно
  в самом неравенстве):

  \begin{multline}
    = \Pr{Z \geq k_0} = \Pr{Z - \E{Z} \geq k_0 - ck_0} \leq
    \exp\left(-\frac{k_0^2(1 - c)^2}{2\left(\E{Z} + \frac{k_0(1 - c)}{3}\right)}\right)
    \leq\\\leq \exp\left(-\frac{k_0(1 - c)^2}{2}(1 + o(1))\right) \asymp n^{-\frac{3}{2}(1 + o(1))}
  \end{multline}

  Тогда вероятность того, что существует компонента, размера больше, чем $k_0$,
  не больше, чем сумма по всем вершинам такой величины, то есть не больше, чем

  \[
    \sum\limits_{i = 1}^n n^{-3/2} \to 0.
  \]

  Заметим, что вместо константы $3$ можно было взять любую константу $2 + \epsilon$.
  Вычисление точной константы остаётся вне нашего курса.
\end{proof}


