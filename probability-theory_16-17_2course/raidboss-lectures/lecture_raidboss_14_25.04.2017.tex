\section{Лекция от 25.04.2017}

\subsection{Процесс броуновского движения}

Одним из самых известных случайных процессов является процесс броуновского
движения, предложенный для моделирования броуновской частицы. Этот процесс
ещё называют винеровским в честь Норберта Винера, одним из первых, кто предложил
моделировать броуновское движение таким способом.

\begin{definition}
  $\{W_t, t \geq 0\}$ называется винеровским процессом, если
  \begin{itemize}
    \item[1.] $W_0 = 0$ почти наверное.
    \item[2.] $W_t$ --- процесс с независимыми приращениями.
    \item[3.] $W_t - W_s \sim \mathcal{N}(0, t - s)$, для любых $0\leq s < t$.
  \end{itemize}
\end{definition}

Пока непонятно, существует ли такой процесс или нет, но позже мы это выясним.
Винеровский процесс, тем не менее, обладает рядом хороших свойств. Первое, что
мы отметим, это то, что винеровский процесс является не только процессом с независимыми
приращениями, но и гауссовским процессом.

\subsection{Гауссовский процесс}

\begin{definition}
  Процесс $\{X_t, t \geq 0\}$ называется гауссовским, если $\forall n \in \N$ и
  для любых $t_1, \ldots, t_n \in T$ случайный вектор $(X_{t_1}, \ldots, X_{t_n})$
  --- гауссовский.
\end{definition}

Также важно ввести две функции, с которыми удобно работать.

\begin{definition}
  $\E{X_t} = A(t)$ называют функцией среднего, а $\cov(X_s, X_t) = r(s, t)$
  ковариационной функцией.
\end{definition}

\begin{definition}
  Функция $r(s, t), s, t \in T$ называется \textit{неотрицательно определенной}
  на $T \times T$,
  если $\forall n \in \N$ и $\forall t_1, \ldots, t_n \in T$, а также
  $\forall x_1, \ldots, x_n \in \R$ выполнено, что

  \[
    \sum\limits_{i, j = 1}^n r(t_i, t_j)x_ix_j \geq 0
  \]   
\end{definition}

Для любого случайного процесса верно, что ковариационная функция неотрицательная.
Давайте это проверим.

\[
  \sum\limits_{i, j = 1}^n \cov(X_{t_i}, X_{t_j})x_ix_j = 
  \cov\left(\sum\limits_{i = 1}^n x_iX_{t_i}, \sum\limits_{j = 1}^n x_jX_{t_j}\right) =
  \cov(X, X) = \D{X} \geq 0
\]

Следующие две теоремы показывают зависимость между гауссовским и винеровским
процессом.

\begin{theorem}
  Пусть $T \subseteq \R$, а $A(t): T \to \R$ и $r(s, t)$ --- симметричная неотрицательно
  неопределенная функция на множестве $T \times T$. Тогда существует гауссовский
  процесс с такими функцией среднего и ковариационной функцией.
\end{theorem}

Оставим мы её без доказательства.

Зато мы предъявим эквивалентное определение винеровского процесса через
гауссовский.

\subsection{Эквивалентное определение винеровского процесса}

\begin{theorem}[Эквивалентное определение винеровского процесса]
  Процесс $\{W_t, t \geq 0\}$ винеровский $\iff$ выполнены следующие три свойства:
  \begin{center}
    \begin{itemize}
      \centering
      \item[1)] $W_t$ --- гауссовский;
      \item[2)] $\E{W_t} = 0$;
      \item[3)] $\cov(W_s, W_t) = \min(s, t)$.
    \end{itemize}
  \end{center}
\end{theorem}

\begin{proof}
  $\boxed{\Longrightarrow}$. Раз $W_t - W_0 = W_t \sim \mathcal{N}(0, t)$, то
  $\E{W_t} = 0$.

  Пусть без ограничения общности $t \geq s$. Вспомним, что винеровский процесс ---
  процесс с независимыми приращениями. Тогда $\cov(W_t, W_s) = 
  \cov(W_t - W_s, W_s) + \cov(W_s, W_s) = 0 + \D{W_s} = s$.

  Для любых $t_1 \leq \ldots \leq t_n$ вектор $(W_{t_1}, \ldots, W_{t_n})$ был получен
  линейным преобразованием вектора $(W_{t_1}, W_{t_2} - W_{t_1}, \ldots, W_{t_n} - W_{t_{n - 1}})$,
  а последний в свою очередь является гауссовским, так как все компоненты независимые
  и гауссовские.

  $\boxed{\Longleftarrow}$. Рассмотрим случайный вектор $(W_{t_n} - W_{t_{n - 1}}, \ldots,
  W_{t_2} - W_{t_1}, W_{t_1})$, где $0 \leq t_1 < t_2 < \ldots < t_n$. Заметим, что
  это гауссовский случайный вектор, как линейное преобразование гауссовского вектора.

  Как мы помним, для доказательства независимости, нужно доказать, что компоненты
  некоррелируемы. Рассмотрим $\cov(W_{t_j} - W_{t_{j - 1}}, W_{t_k} - W_{t_{k - 1}})$
  при $j > k$. Мы хотим понять, чему равна такая ковариация.

  \[
    \cov(W_{t_j} - W_{t_{j - 1}}, W_{t_k} - W_{t_{k - 1}}) = 
    \cov(W_{t_j}, W_{t_k}) - \cov(W_{t_{j - 1}}, W_{t_k}) -
    \cov(W_{t_j}, W_{t_{k - 1}}) + \cov(W_{t_{j - 1}}, W_{t_{k - 1}})
  \]

  Каждое слагаемое раскрывается однозначно, так как мы уже выяснили, чему равна
  ковариация $\cov(W_s, W_t)$, поэтому это всё равно

  \[
    t_k - t_k - t_{k - 1} + t_{k - 1} = 0.
  \]

  Вектор гауссовский, значит и каждая компонента является нормальной величиной.
  Притом с нулевым средним. Посчитаем дисперсию при $t > s$:

  \[
    \D{W_t - W_s} = \cov(W_t - W_s, W_t - W_s) = t + s - s - s = t - s
  \]

  То есть $W_t - W_s \sim \mathcal{N}(0, t - s)$.

  Раз $W_t$ --- гауссовский процесс, то $\E{W_0} = 0$ по условию и $\D{W_0} = 
  \cov(W_0, W_0) = \min(0, 0) = 0$, значит $W_0 = 0$ почти наверное.
\end{proof}

\subsection{Свойство траекторий винеровского процесса}

Винеровский процесс устроен достаточно сложно по отношению к пуассоновскому, но
траектории ведут себя весьма интересно. Здесь будут достаточно обзорные свойства,
почти все без доказательства.

\textbf{Свойство 1.} Траектория винеровского процесса является непрерывной почти всюду. Давайте
  поймём, как это реализуется в математическом формализме.

\begin{definition}
  Процесс $\{Y_t, t \geq 0\}$ называется \textit{модификацией} процесса $\{X_t, t \geq 0\}$,
  если $\forall t \in T$ следует, что $\Pr{X_t = Y_t} = 1$. В этом случае говорят,
  что процессы $X_t$ и $Y_t$ эквивалентны.
\end{definition}

На самом деле траектории могут иметь совершенно разные свойства у эквивалентных
процессов. Рассмотрим показательный пример.

\begin{example}
  Пусть $(\Omega, \F, \Pr) = ([0, 1], \B[0, 1], mes)$, где $mes$ --- мера Лебега.
  $X_t(\omega) = 0 \ \forall t$, а $Y_t(\omega) = \I\{\omega = t\}$. Процессы
  $X_t$ и $Y_t$ эквивалентны, но у $X_t$ траектории непрерывны, а у $Y_t$ всегда
  существует разрыв.
\end{example}

Ключевой теоремой для обсуждения траекторий винеровского процесса является теорема
Колмогорова о существовании непрерывной модификации.

\begin{theorem}[Колмогорова о существовании непрерывной модификации]
  Пусть $\{X_t, t \in [a, b]\}$ --- случайный процесс и существуют $C, \alpha,
  \epsilon > 0$ с условием

  \[
    \E{|X_t - X_s|^\alpha} \leq C|t - s|^{1+ \epsilon} \ \forall \ t, s \in [a, b]
  \]

  Тогда у $X_t$ существует модификация, что все траектории непрерывны.
\end{theorem}

Заметим, что условие $\epsilon > 0$ нельзя заменить на $\epsilon = 0$, иначе пуассоновский
процесс был бы непрерывным (так как $\E{|X_t - X_s|} = \lambda|t - s|$), что однозначно не так
с вероятностью один.

Доказывать теорему мы не будем, но выведем из неё следствие для винеровского процесса.

\begin{lemma}
  У винеровского процесса существует непрерывная модификация.
\end{lemma}

\begin{proof}
  Рассмотрим $W_t - W_s \sim \mathcal{N}(0, |t - s|)$, тогда

  \[
    \E{|W_t - W_s|^4} = 3|t - s|^2
  \]

  Это действительно так (вспоминаем основной курс теории вероятностей). Это как
  раз то, что нам нужно для теоремы Колмогорова при $C = 3, \alpha = 4, \epsilon = 1$.

  Тогда разобьём всю положительную полуось на полуинтервалы $[n, n + 1), n \in \Z_+$ 
  и на каждом  из них существует непрерывная модификация (правую точку оставим для
  следующего набора модификаций) $W_t \ \forall t \geq 0$,
  а значит разрывы могут
  быть только в целых точках. Так как их счётное число, то вероятность иметь разрыв
  у модификации равна нулю, так как модификации равны изначальному процессу с вероятностью
  один.
\end{proof}


\textbf{Свойство 2.} Траектория винеровского процесса c вероятностью один не 
дифференцируема
ни в одной точке на $[0, +\infty)$.

То есть траекторию такого процесса нарисовать нет никакой возможности, так как
график ведет себя нерегулярно.

\textbf{Свойство 3.} Закон повторного логарифма. То же самое, что и у случайного
блуждания на прямой, а именно

\[
  \Pr{\varlimsup\limits_{t \to +\infty} \frac{W_t}{\sqrt{2t\ln\ln t}} = 1} = 1
\]

Доказывать этот закон мы тоже не будем, но выведем ряд полезных
свойств. Так же, как и в случайном блуждании получаем, что (так как $W_t \sim -W_t$)

\[
  \Pr{\varliminf\limits_{t \to +\infty} \frac{W_t}{\sqrt{2t\ln\ln t}} = -1} = 1
\]

Но и выполнен закон повторного логарифма в окрестности нуля.

\begin{lemma}[Локальный закон повторного логарифма]
  \[
    \Pr{\varlimsup\limits_{t \to 0^+} \frac{W_t}{\sqrt{2t\ln\ln \frac1t}} = 1} = 1
  \]
\end{lemma}
  
\begin{proof}
  Рассмотрим $B_t = tW_{\frac1t}, t > 0$ и 0, если $t = 0$. 
  Докажем, что $B_t$ --- винеровский процесс.
  Для этого воспользуемся эквивалентным определением.

  Пусть $t_1, \ldots, t_n$ --- числа, тогда $(B_{t_1}, \ldots, B_{t_n})$ --- гауссовский
  вектор, как линейная комбинация гауссовского вектора $(W_{\frac{1}{t_1}},\ldots,
  W_{\frac{1}{t_n}})$.

  С математическим ожиданием ещё проще --- $\E{B_t} = \E{tW_{\frac1t}}$, но $t$
  --- это константа, а винеровский изначальный процесс имеет среднее нуль, поэтому
  $\E{B_t} = 0$.

  Осталось разобраться с ковариацией. $\cov(B_t, B_s) = st\min\left(\frac{1}{t},
  \frac{1}{s}\right) = \frac{st}{\max(s, t)} = \min(s, t)$.

  Откуда из закона повторного логарифма

  \[
    \Pr{\varlimsup\limits_{t \to +\infty} \frac{tW_{\frac{1}{t}}}{\sqrt{2t\ln\ln t}} = 1} = 1
  \]

  Делаем замену, сокращаем, получаем, что

  \[
    \Pr{\varlimsup\limits_{t \to 0^+} \frac{W_{t}}{\sqrt{2t\ln\ln \frac1t}} = 1} = 1
  \]
\end{proof}

\subsection{Марковские свойства винеровского процесса}

С траекториями мы разобрались, теперь давайте применять теорию про мартингалы
и марковские моменты. Легко проверить, что 
$\{W_t, t \geq 0\}$ является мартингалом относительно естественной
фильтрации (действительно, 
$\E{W_t \given \F_s} = \E{W_t - W_s \given \F_s} + \E{W_s \given \F_s} = 
\E{W_t - W_s} + W_s = W_s$).

\begin{theorem}[Марковское свойство винеровского процесса]
  При любом фиксированном $T > 0$ процесс $Y_t = W_{T + t} - W_T, t \geq 0$
  винеровский и не зависит от сигма алгебры $\F_T$.
\end{theorem}

\begin{proof}
  Доказательство немедленно следует из независимости приращений. Кроме того,
  надо заметить, что для проверки независимости $\F_T$ и $\sigma(Y) = \F^Y$ 
  достаточно установить, что $\sigma(W_{t_1}, \ldots, W_{t_n})$ и 
  $\sigma(Y_{u_1}, \ldots, Y_{u_m})$ независимы при любых
  $0 \leq t_1 < t_2 < \ldots \leq T$ и $0 \leq u_1 < u_2 < \ldots < u_m$. Это
  действительно правда, так как можно преобразовать первую сигма алгебру в
  $\sigma(W_{t_1}, W_{t_2} - W_{t_1}, \ldots, W_{t_n} - W_{t_{n - 1}})$ и тогда
  независимость с $Y_i$ очевидна.
\end{proof}

Указанное свойство сохраняется при замене $T$ на случайную величину, но не любую,
а принадлежащую определенному классу.

\begin{definition}
  $\sigma$-алгебра $\F_\tau$ состоит из событий $A \in \F$ таких, что для любого
  $t > 0$

  \[
    A \cap \{\tau \leq t\} \in \F_t
  \]
\end{definition}

Легко показать, что $\F_\tau$ в самом деле $\sigma$-алгебра.

Перед тем, как доказывать теорему о строго марковском свойстве, докажем пару утверждений.

\begin{lemma}[О равенстве по распределению]
  Пусть $\xi, \eta$ --- два случайных вектора размерности $n$, тогда
  $\xi \eqdist \eta \iff \forall \ f: \R^n \to \R$ ограниченной и непрерывной
  следует, что $\E{f(\xi)} = \E{f(\eta)}$.
\end{lemma}

\begin{proof}
  В прямую сторону утверждение очевидно.
  В обратную сторону возьмём $f(x) = \cos\langle t, x \rangle$ и 
  $f(x) = \sin\langle t, x \rangle$, откуда получаем, что характеристические
  функции совпадают, значит по теореме единственности случайные векторы одинаково
  распределены.
\end{proof}

\begin{lemma}[Независимости случайного вектора и сигма алгебры]
  Пусть $\xi$ --- случайный вектор. Он независим с $\mathscr{C} \iff \forall
  \ A \in \mathscr{C}$ и $f: \R^n \to \R$ ограниченной и непрерывной выполнено,
  что $\E{f(\xi)\I_A} = \E{f(\xi)}\Pr{A}$.
\end{lemma}

\begin{proof}
  В прямую сторону это вывод из определения независимости.
  В обратную введем случайный вектор $(\xi, \I_A)$. Его характеристическая функция
  равна 
  \begin{multline}
    \phi(\overline{\lambda}, \lambda_0) = \E{e^{i\sum\limits_{j = 1}^n \xi_j
    \lambda_j + i\lambda_0 \mathbf{I}_A}} =
    \E{e^{i\sum\limits_{j = 1}^n \xi_j
    \lambda_j + i\lambda_0}  \mathbf{I}_A} + \E{e^{i\sum\limits_{j = 1}^n \xi_j
    \lambda_j} \mathbf{I}_{\overline{A}}} =\\=
    \phi_\xi(\overline{\lambda})e^{i\lambda_0}\Pr{A} + \phi_\xi(\overline{\lambda})
    \Pr{\overline{A}} = \phi_{\xi}(\overline{\lambda})\phi_{\mathbf{I}_A}(\lambda_0)
  \end{multline}

  То есть произведение разбилось в произведение компонент, откуда и следует
  независимость (мы пользовались ограниченностью синуса и косинуса).
\end{proof}

\begin{theorem}[Строго марковское свойство]
  Пусть $\tau(\omega)$ --- момент остановки. Тогда процесс $Z_t(\omega) = 
  W_{\tau(\omega) + t} - W_{\tau(\omega)}$ --- винеровский процесс, не зависящий
  от $\F_\tau$.
\end{theorem}

\begin{proof}
  Введем случайные величины $\tau_n(\omega) = k2^{-n}$, если $\tau(\omega) \in
  [(k - 1)2^{-n}, k2^{-n})$. Ясно, что $\tau_n(\omega)$ --- марковские
  моменты относительно естественной фильтрации $\mathbb{F}^W$:

  \[
    \{\tau_n \leq t\} = \{\tau_n \leq k2^{-n}\}
  \]
  где $k = \lfloor t2^n \rfloor$.

  Последнее же равно $\{\tau < k2^{-n}\}$, так как мы принимаем значения и только их
  не больше $k2^{-n}$ по построению. Поэтому

  \[
    \{\tau < k2^{-n}\} \in \mathbb{F}^W_{k2^{-n}} \subseteq \mathbb{F}^W_t.
  \]

  Также ясно, что $\tau_n(\omega) \downarrow \tau(\omega)$ при $n \to +\infty$.

  Теперь рассмотрим событие $B \in \F_\tau$ и докажем, что оно независимо с
  $Z_{t_1}, \ldots, Z_{t_m}$. Достаточно по лемме о независимости проверить, что

  \[
    \E{\mathbf{I}_B f(Z_{t_1}, \ldots, Z_{t_m})} = 
    \Pr{B}\E{f(Z_{t_1}, \ldots, Z_{t_m})}
  \]

  для всех ограниченных и непрерывных функций $f$.

  Положим 

  \[
    \zeta = f(W_{\tau + t_1} - W_\tau, \ldots, W_{\tau + t_m} - W_\tau)
    \text{ и } \zeta_n = f(W_{\tau_n + t_1} - W_{\tau_n}, \ldots, W_{\tau_n + t_m} -
     W_{\tau_n})
  \]

  Из непрерывности $f$ и $W_t$ следует, что $\zeta_n \to \zeta$ при $n \to +\infty$
  почти наверное. Так как $|f| < +\infty$, тогда $|\zeta_n| \leq |f|$ и по теореме
  Лебега
  $\E{\I_B\zeta} = \lim\limits_{n \to +\infty} \E{\I_B \zeta_n}$. Теперь распишем
  последнее

  \[
    \E{\mathbf{I}_B\zeta_n} = \E{\sum\limits_{k = 1}^{+\infty}\mathbf{I}_B
    \mathbf{I}_{\{\tau_n = k2^{-n}\}} \zeta_n} =
    \E{\sum\limits_{k = 1}^{+\infty}\mathbf{I}_{B\cap\{\tau_n = k2^{-n}\}}
    f(W_{\tau_n + t_1} - W_{\tau_n}, \ldots, W_{\tau_n + t_m} -
     W_{\tau_n})}
  \]

  Событие $B \cap \{\tau_n = k2^{-n}\}$ принадлежит $\F_{k2^{-n}}$, так как
  $B \cap \{\tau_n = k2^{-n}\} = (B \cap \{\tau_n \leq k2^{-n}\}) \setminus
  (B \cap \{\tau_n < k2^{-n}\})$ (а последнее в свою очередь равно $\bigcup
  \limits_{q = 1}^{+\infty}\left(B \cap \left\{\tau \leq t - \frac{1}{q}\right\}\right)$),
  поэтому заменим $\tau_n$ на $k2^{-n}$ и воспользуемся обычным марковским свойством
  винеровского процесса (а именно независимостью). Более подробно:

  \begin{multline}
    \E{\mathbf{I}_{B\cap\{\tau_n = k2^{-n}\}}
    f(W_{k2^{-n} + t_1} - W_{k2^{-n}}, \ldots, W_{k2^{-n} + t_m} -
     W_{k2^{-n}})} =\\=\E{\mathbf{I}_{B\cap\{\tau_n = k2^{-n}\}}}\E{
    f(W_{k2^{-n} + t_1} - W_{k2^{-n}}, \ldots, W_{k2^{-n} + t_m} -
     W_{k2^{-n}})} =\\= 
     \Pr{B \cap \{\tau_n = k2^{-n}\}}\E{f(\hat{W}_{t_1}, \ldots, \hat{W}_{t_m})},
  \end{multline}
  где $\hat{W}_t = W_{k2^{-n} + t} - W_{k2^{-n}}$.

  Заметим, что распределение $\hat{W}_t$ совпадает с распределением $W_t$, так
  как они оба распределены, как $\mathcal{N}(0, t)$. Поэтому заменим матожидание.

  \[
    \E{\mathbf{I}_B\zeta_n} = \Pr{B}\E{f(W_{t_1}, \ldots, {W}_{t_m})}
  \]

  Если устремить $n$ к бесконечности, получим, что $\E{\I_B\zeta} = 
  \Pr{B}\E{f(W_{t_1}, \ldots, {W}_{t_m})}$. Возьмём $B = \Omega$, откуда вытекает,
  что

  \[
    \E{f(W_{t_1}, \ldots, {W}_{t_m})} = \E{f(Z_{t_1}, \ldots, Z_{t_m})}
  \]

  Значит мы можем написать, что $\E{\I_B\zeta} = 
  \Pr{B}\E{f(W_{t_1}, \ldots, {W}_{t_m})} = \Pr{B}\E{f(Z_{t_1}, \ldots, Z_{t_m})}$,
  что нам и требовалось для независимости.

  А мы доказали, что если для любой ограниченной функции матожидания от этих
  функций совпадают, то векторы распределены одинаково. Значит $Z$ --- винеровский
  процесс.
\end{proof}
