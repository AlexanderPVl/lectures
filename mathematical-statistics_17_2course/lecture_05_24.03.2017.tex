\section{Лекция 5 от 24.03.2017}
\subsection{Экспоненциальное семейство распределений}
Мы уже доказали неравенство Рао-Крамера: при определенных ограничениях на тип статистической структуры (гладкость параметрического семейства, регулярность функции) несмещенная оценка $T(Y)$ функции $\tau(\theta)$ удовлетворяет неравенству
\[
    \D{T} \geqslant \frac{\big(\tau'(\theta)\big)^2}{I_n}.
\]

При этом равенство достигается, если и только если имеет место соотношение
\begin{gather}
    \dlnpn{y} = c(\theta)\big( T(Y) - \tau(\theta)\big).
\end{gather}

Отсюда мы сделали вывод, что для эффективной оценки $T$ функции $\tau(\theta)$ всегда выполнено данное соотношение. При этом никакие функции от $\theta$, кроме линейных преобразований $\tau$ не имеют эффективных оценок. Однако формулировка в терминах частной производной не всегда удобна, поэтому часто данное равенство переписывают в интегральном виде. Проинтегрировав соотношение из неравенства Рао-Крамера, мы получаем равенство, которое приводит нас к понятию \emph{экспоненциальных семейств}.

\begin{definition}
    Экспоненциальная модель, или экспоненциальное семейство распределений, имеет место, если для плотности (в дискретном случае --- вероятности) выполнено равенство:
    \[
        p(x, \theta) = \exp\Big[A(\theta)B(x) + C(\theta) + D(x)\Big],
    \]
    где $A, B, C, D$ --- некоторые функции соответствующих аргументов.
\end{definition}

С другой стороны, если имеет место данное равенство, то в качестве $\tau(\theta)$ и $T(Y)$ выступают следующие функции:
\[
    \tau(\theta) = -\frac{C'(\theta)}{A'(\theta)}, \qquad T(Y) = \frac1n \sum\limits_{i=1}^n B(X_i).
\]
Это простое упражнение предлагаем читателю проделать самостоятельно. Таким образом, если мы находимся в условиях экспоненциального семейства распределений, то, во-первых, мы можем сказать, для каких функций от $\theta$ эффективная оценка существует, а во-вторых, как она выглядит.

Экспоненциальные семейства встречаются достаточно часто и охватывают все известные нам распределения (пуассоновское, бернуллиевское, нормальное, экспоненциальное и т.д.).

Неравенство Рао-Крамера дает нам нижнюю оценку дисперсии любой несмещенной оценки, что само по себе хорошо. Однако помимо ограничений на тип функции распределения у этого неравенства имеется еще один важный недостаток: неизвестный параметр $\theta$ есть просто действительное число, то есть он одномерный, поэтому охватывает лишь часть возможных моделей. Возникает вопрос: существует ли многомерное обобщение неравенства Рао-Крамера? Оказывается, существует, но это уже выходит за рамки нашего курса.

\subsection{Достаточные статистики}

В наше время в прикладных задачах статистики объем данных порой может быть колоссальным. Однако если мы работаем в рамках параметрической модели (зависящей от параметра $\theta$) и нас интересует только оценка и некое заключение о параметре $\theta$, то, возможно, нет смысла сохранять данные обо всех наблюдениях, а достаточно хранить их в каком-либо агрегированном виде.

\begin{definition}
    Функция от повторной выборки (статистика) $T(Y) = T(X_1, \ldots, X_n)$ называется \emph{достаточной статистикой}, если условное распределение $Y = (X_1, \ldots, X_n)$ относительно $T$ (при фиксированном значении статистики $T$) не зависит от $\theta$.
\end{definition}

Напомним, что распределение вектора --- это функция $\Pr{Y \in B}$, где $B$ --- борелевское множество в $\R^n$. В определении же идет речь об условном распределении $Y$, то есть функции
\[
    \Pr{Y \in B \given T} = \E{\mathrm{I}\{Y \in B\} \given T}.
\]
Это случаная величина, и мы хотим, чтобы она не зависела от $\theta$ (хотя $T, Y$ зависят от $\theta$). Но существует ли такая случайная величина? Оказывается, да. Приведем тривиальный пример: $T(Y) = Y$ (в качестве оценки взята сама выборка). При зафиксированном значении выборки условное математическое ожидание вырождается в одну точку --- зафиксированное значение. Однако, такая достаточная статистика неинтересна, так как она не редуцировала данные --- нам все еще нужно хранить всю выборку. Рассмотрим менее тривиальную достаточную статистику

\begin{example}
    Пусть имеется повторная выборка $Y = (X_1, \ldots, X_n)$ из $\mathcal{L}(X)$, где $X \sim Ber(\theta)$. В качестве оценки $T(Y)$ возьмем сумму $X_1 + \ldots + X_n$ (можно рассматривать выборочное среднее, но это несколько усложнит вычисления). Рассмотрим условную вероятность
    \[
        \Pr{X_1 = a_1, \ldots, X_n = a_n \given T = t} = \frac{\Pr{X_1 = a_1, \ldots, X_n = a_n, T = t}}{\Pr{T = t}}.
    \]

    Здесь возможны два варианта. Если $a_1 + \ldots + a_n \neq t$, то вероятность в числителе равна нулю и точно не зависит от $\theta$. Поэтому будем рассматривать те значения $a_1, \ldots, a_n, t$, при которых $a_1 + \ldots + a_n = t$. Но в этом случае событие $\{T = t\}$ вытекает из событий $\{X_1 = a_1\}, \ldots, \{X_n = a_n\}$, поэтому вероятность в числителе равна $\Pr{X_1 = a_1, \ldots, X_n = a_n}$, то есть значению функции правдоподобия в точке $(a_1, \ldots, a_n)$, а формулу для функции правдоподобия бернуллиевского распределения мы уже знаем. Заметим, что в нашем случае $T$ есть сумма бернуллиевских случайных величин, то есть $T \sim Bin(n, \theta)$. Теперь мы можем посчитать искомую условную вероятность. Обозначим $S = a_1 + \ldots + a_n$, тогда $t = S$ и
    \[
        \Pr{X_1 = a_1, \ldots, X_n = a_n \given T = t} = \dfrac{\theta^S(1-\theta)^{n-S}}{C_n^t\  \theta^t (1-\theta)^{n-t}} = \dfrac{1}{C_n^t}.
    \]

    Получили функцию, не зависящую от $\theta$. Вывод: $X_1, \ldots, X_n$ --- достаточная статистика, что эквивалентно тому, что выборочное среднее есть также достаточная статистика. Таким образом, для того чтобы построить оценку параметра $\theta$, достаточно знать сумму $X_1, \ldots, X_n$, а не хранить всю выборку (более подробное обоснование нам даст теорема Рао-Блэкуэлла-Колмогорова).
\end{example}

\begin{remark}
    Любая биективная функция от достаточной статистики есть достаточная статистика.
\end{remark}

Для того чтобы выяснить, что выборочное среднее выборки из бернуллиевского распределения является достаточной статистикой, нам пришлось проделать некоторую работу. Но это лишь самое простое распределение, поэтому хотелось бы иметь некий инструмент для определения достаточных статистик. И такой инструмент есть.

\begin{theorem}[Критерий факторизации]
    Статистика $T$ является достаточной, если и только если $p_n(y, \theta) = g(T(y), \theta)h(y)$, где $p_n$ --- функция правдоподобия.
\end{theorem}

В приведенном выше примере мы могли бы, используя эту теорему, сразу заключить, что $X_1 + \ldots + X_n$ является достаточной статистикой. Действительно, в функцию правдоподобия выборка входит лишь в виде суммы ее элементов, что и является достаточным условием теоремы.

\begin{proof}[Доказательство]
    Докажем теорему для случая, когда функция правдоподобия есть произведение вероятностей. Случай плотностей читателю предлагается разобрать самостоятельно. Пусть имеется достаточная статистика $T$ и $T(y) = t$. Заметим, что событие $\{Y = y\}$ вложено в событие $\{T(Y) = t\}$. Тогда
    \[
        p_n(y, \theta) = \Pr_\theta(Y = y) = \Pr_\theta(Y = y, T(Y) = t) = \Pr_\theta(T(Y) = t) \Pr_\theta(Y = y \ | \ T(Y) = t).
    \]
    Ясно, что первый множитель зависит от $T(y)$ и $\theta$. При этом второй множитель не зависит от $\theta$, так как $T$ --- достаточная статистика. Получили необходимое выражение.

    Обратно, пусть $p_n(y, \theta) = g(T(y), \theta)h(y)$. При $y$, для которых $T(y) = t$ (в противном случае условная вероятность равна нулю), имеет место следующее:
    \[
        \Pr_\theta(Y = y \ | \ T(Y) = t) = \frac{\Pr_\theta(Y = y, T(Y) = t)}{\Pr_\theta(T(Y) = t)}.
    \]
    Числитель есть не что иное, как $\Pr_\theta(Y = y)$, так как $\{Y = y\} \subset \{T(Y) = t\}$. Знаменатель же распишем по формуле полной вероятности и воспользуемся условием:
    \[
        \frac{\Pr_\theta(Y = y)}{\sum\limits_{y': \ T(y') = t}\Pr_\theta(Y=y')} = \frac{g(t, \theta)h(y)}{\sum\limits_{y': \ T(y') = t}g(t, \theta)h(y')} = \frac{h(y)}{\sum\limits_{y': \ T(y') = t}h(y')}.
    \]
    Получили функцию, не зависящую от $\theta$. Критерий доказан.
\end{proof}

Рассмотрим простой пример применения критерия факторизации.

\begin{example}
    Рассмотрим повторную выборку $Y = (X_1, \ldots, X_n)$ из нормального распределения с двумя неизвестными параметрами. То есть $Y$ из $\mathcal{L}(X)$, где $X \sim \mathcal{N}(\sigma_1, \sigma_2^2)$. Запишем функцию правдоподобия для выборки, как произведение плотностей нормальных случайных величин, и преобразуем ее к следующему виду:
    \[
        p_n(y, \sigma) = \frac{1}{(\sqrt{2 \pi}\sigma_2)^n} \exp\Big[-\frac{1}{2\sigma_2^2} \sum\limits_{i=1}^n(x_i - \overline{x})^2 - \frac{n(\overline{x} - \sigma_1)^2}{2\sigma_2^2} \Big]
    \]
    Здесь мы воспользовались тем, что
    \[
        -\sum\limits_{i=1}^n(x_i - \sigma_1)^2 = -\sum\limits_{i=1}^n(x_i - \overline{x})^2 - n(\overline{x} - \sigma_1)^2.
    \]
    Отсюда можно заключить, что $T(Y) = (\overline{X}, \ S^2)$ является двумерной достаточной статистикой по критерию факторизации.
\end{example}

\begin{theorem}[Рао, Блэкуэлл, Колмогоров]
    Если оптимальная оценка существует, то она является функцией от достаточной статистики.
\end{theorem}

\begin{proof}
    Пусть $T$ --- достаточная статистика, а $T_1$ --- несмещенная оценка для $\tau(\theta)$. Положим $H(T) = \E{T_1 \given T}$ --- измеримая функция от $T$. Запишем формулу полной вероятности для условного математического ожидания:
    \[
        \E H = \E[\E{T_1 \given T}] = \E T_1 = \tau(\theta),
    \]
    поскольку оценка $T_1$ несмещенная. То есть $H(T)$ есть также несмещенная оценка $\tau(\theta)$. Покажем теперь, что $\D H(T) \leqslant \D T_1$ для любого значения параметра $\theta \in \Theta$. Мы знаем, что для любой измеримой функции $f(X, Y)$, у которой существует матожидание, выполнено соотношение $\E f(X, Y) = \E[\E{f(X, Y) \given X}]$ (это снова формула полной вероятности). В этой формуле возьмем $X = T,\ Y = T_1$, а $f(X, Y) = \E{(Y - H(X))(H(X) - \tau(\theta))}$. Получим следующее:
    \begin{multline}
        \E\big[(T_1 - H(T))(H(T) - \tau(\theta))\big] = \E\Big[\E\big[(\underbrace{H(T) - \tau(\theta)}_{\text{функция от $T$}}) (T_1 - H(T)) \ | \ T\big]\Big] = \\ = \E\Big[(H(T) - \tau(\theta))\E\big[(T_1 - H(T)) \ | \ T\big]\Big] = 0.
    \end{multline}
    Последнее равенство следует из линейности условного математического ожидания и определения $H(T)$. Теперь рассмотрим дисперсию $T_1$:
    \begin{multline}
        \D T_1 = \E{T_1 - \tau(\theta)}^2 = \E{T_1 - H(T) + H(T) - \tau(\theta)}^2 = \\\\ = \underbrace{\E{T_1 - H(T)}^2}_{\geqslant \ 0} + 2\underbrace{\E\big[(T_1 - H(T))(H(T) - \tau(\theta))\big]}_{= \ 0} + \underbrace{\E{H(T) - \tau(\theta)}^2}_{= \ \D H(T)} \geqslant \D H(T).
    \end{multline}

    Пусть теперь $T_1$ --- какая-то оптимальная оценка. Взяв условное математическое ожидание $T_1$ от $T$, мы получили несмещенную оценку $H$, являющуюся функцией от достаточной статистики. При этом дисперсия $H$ не превосходит дисперсии $T_1$, а значит, равна ей ввиду оптимальности $T_1$. Из единственности оптимальной оценки заключаем, что $T_1 = H$ с вероятностью 1.
\end{proof}

Мы получили довольно сильный результат: оказывается, оптимальную статистику можно искать, как функцию от достаточной статистики. Таким образом, для оценки параметра $\theta$ нам достаточно знать некую статистику выборки, а не всю выборку. Теперь рассмотрим еще один пример применения критерия факторизации.

\begin{example}
    Пусть $Y = (X_1, \ldots, X_n)$ --- повторная выборка из $\mathcal{L}(X)$, где $X \sim U[0, \theta]$. Заметим, что данная модель не является регулярной. Однако, мы можем найти достаточную статистику для параметра $\theta$. Запишем для начала функцию правдоподобия:
    \[
        p_n(y, \theta) = \begin{cases} \frac{1}{\theta^n}, & x_{(1)} \geqslant 0,\  x_{(n)} \leqslant \theta; \\ 0, & \text{иначе}. \end{cases}
    \]
    Можно записать это равенство в терминах индикаторов. Пусть $g(z) = \mathrm{I}\{z \geqslant 0\}$. Тогда
    \[
        p_n(y, \theta) = \frac{g(\theta - x_{(n)})}{\theta^n} g(x_{(1)}),
    \]
    где первый множитель зависит от $\theta$ и $x_{(n)}$, а второй --- от выборки. Тогда по критерию факторизации статистика $T(Y) = X_{(n)}$ является достаточной.
\end{example}
