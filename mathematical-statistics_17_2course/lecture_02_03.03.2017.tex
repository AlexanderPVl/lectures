\section{Лекция 2 от 03.03.2017}
\subsection{Вариационный ряд. Порядковые статистики}
На прошлой лекции мы ввели квантили. Для их оценивания можно ввести так 
называемые порядковые статистики. Перед этим введём понятие вариационного ряда.
\begin{definition}
	Пусть есть некоторая реализация \((x_{1}, \dots, x_{n})\). Построим по ней 
	набор \((x_{(1)}, \dots, x_{(n)})\) такой, что \(x_{(1)} \leq x_{(2)} \leq 
	\dots \leq x_{(n)}\). Полученный набор называется \emph{вариационым 
	рядом}.
\end{definition}
На прошлой лекции мы показали, что \(x_{(k)}\) есть квантиль порядка \(i/k\) 
для эмпирической функции распределения.

\begin{definition}
	Пусть есть выборка \((X_{1}, \dots, X_{n})\). Тогда \(k\)-й 
	\emph{порядковой статистикой} называется случайная величина \(X_{(k)}\), 
	которая на любой реализации выборки принимает значение \(x_{(k)}\).
\end{definition}
Несложно понять, какое распределение имеет \(k\)-я порядковая статистика. 
Найдём его.
\begin{theorem}
	Пусть \((X_{1}, \dots, X_{n})\)~--- случайные вектор из независимых и 
	одинаково распределённых случайных величин с функцией распределения 
	\(F(x)\). Тогда
	\[
		\Pr{X_{(k)} \leq y} = \sum_{i = k}^{n} C_{n}^{i}F^{i}(y)(1 - 
		F(y))^{n - i}.
	\]
\end{theorem}
\begin{proof}
	Для доказательства этого утвердждения сделаем одно наблюдение. Если среди 
	\(n\) случайных величин хотя бы \(k\) из них больше \(y\), то и \(k\)-я 
	порядковая статистика тоже будет больше \(y\). Тогда, введя величину 
	\(\mu_{n}(y)\), равную количеству случайных величин, больших \(y\), 
	получаем, что
	\[
		\Pr{X_{(k)} \leq y} = \Pr{\mu_{n}(y) \geq k}, \text{ где } \mu_{n}(y) = 
		\sum_{k = 1}^{n} \mathrm{I}\{X_{k} \leq y\}.
	\]
	
	Теперь заметим, что \(\mu_{n}(y) \sim \mathrm{Bin}(n, F(y))\), так как 
	\(\mathrm{I}\{X_{k} \leq y\} \sim \mathrm{Bern}(F(y))\). Тогда 
	\[
		\Pr{X_{(k)} \leq y} = \sum_{i = k}^{n} \Pr{\mu_{n}(y) = i} = \sum_{i = 
		k}^{n} C_{n}^{i}F^{i}(y)(1 - F(y))^{n - i}. \qedhere
	\]
\end{proof}

\subsection{Точечные оценки}
Вернёмся к статистической структуре. Ранее говорилось, что общая задача 
статистики состоит в том, что нужно построить <<наилучшую>> вероятностную меру 
по результатам измерений. Другими словами, мы оцениваем параметры меры. Сам вид 
меры обычно выбирается исследователем из списка известных и соответствующих 
задаче: например, нормальное, экспоненциальное или же биномилаьное.
\begin{definition}
	\emph{Оценка} (или \emph{статистка})~--- это борелевская функция от выборки.
\end{definition}

Теперь обратим внимание на слово <<наилучшую>>. Вообще, что это значит? Как 
понять, что оценка будет в каком-то смысле лучше другой? Для этого введём два 
понятия: несмещённость и состоятельность.
\begin{definition}
	Оценку \(T = T(X_{1}, \dots, X_{n})\) будем называть \emph{несмещённой} 
	оценкой параметра \(\theta\), если \(\E{T} = \theta\) для любого \(\theta 
	\in \Theta\).
\end{definition}
\begin{definition}
	Оценку \(T = T(X_{1}, \dots, X_{n})\) будем называть \emph{состоятельной} 
	оценкой параметра \(\theta\), если \(T \prto \theta\)для любого \(\theta 
	\in \Theta\) при \(n \to \infty\).
\end{definition}

Но с этими видами оценок есть проблемы. Например, они могут просто не 
существовать.
\begin{problem}
	Пусть \(\xi \sim \mathrm{Pois}(\theta)\). Докажите, что не существует 
	несмещённой оценки для \(1/\theta\).
\end{problem}
\begin{proof}
	Достаточно показать, что ни для одной функции \(T = T(\xi)\) её матожидание 
	не будет равно \(1/\theta\). Предположим обратное:
	\[
		\frac{1}{\theta} = \E{T(\xi)} = \sum_{k = 0}^{\infty} 
		T(k)\frac{\theta^{k}}{k!}e^{-\theta} \iff \frac{e^{\theta}}{\theta} = 
		\sum_{k = 0}^{\infty} 
		\frac{T(k)}{k!}\theta^{k}
	\]
	
	Устремляя \(\theta\) к нулю, получаем, что \(T(0) = +\infty\). Но тогда 
	\(\E{T(\xi)} = +\infty\).
\end{proof}