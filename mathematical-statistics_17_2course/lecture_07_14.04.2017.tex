\section{Лекция 7 от 14.04.2017}
\subsection{Оценки максимального правдоподобия. Продолжение}
Продолжим обсуждать оценки максимального правдоподобия.
\begin{point}
	Если оценка максимального правдоподобия существует и единственна, то она 
	является функцией от достаточной статистики.
\end{point}
\begin{proof}
	Пусть \(T\)~--- достаточная статистика. Тогда по критерию факторизации для 
	любого \(\theta \in \Theta\)
	\[
		p_{n}(y; \theta) = g(T(y), \theta)h(y).
	\]
	
	Теперь найдём оценку максимального правдоподобия по определению:
	\[
		p_{n}(y; \theta^{*}) = \sup_{\theta \in \Theta} p_{n}(y; \theta) = 
		\sup_{\theta \in \Theta} g(T(y), \theta)h(y) = h(y)g(T(y), \theta^{*}). 
		\qedhere
	\]
\end{proof}

В утверждении требуется единственность оценки максимального правдоподобия. Но 
есть одна проблема: она не обязательно единственна. 
\begin{example}
	Пусть \((X_{1}, \dots, X_{n})\)~--- выборка из равномерного распределения 
	на \([\theta, \theta + 1]\). Тогда функция правдоподобия равна
	\[
		p_{n}(x_{1}, \dots, x_{n}; \theta) =
		\begin{cases}
			1,& \theta \leq x_{(1)} \leq x_{(n)} \leq \theta + 1, \\
			0,& \text{иначе}.
		\end{cases}
	\]
	
	Тогда на \(\theta\) накладываются следующие ограничения: \(x_{(n)} - 1 \leq 
	\theta \leq x_{(n)}\). Если \(\theta\) удовлетворяет этому неравенству, то 
	функция правдоподобия равна 1, и это есть максимум. Тогда оценкой 
	максимального правдоподобия является любая точка из отрезка \([X_{(n)} - 1, 
	X_{(n)}]\), коих явно больше одной.
\end{example}

Такое многообразие, конечно, не говорит в пользу оценок максимального 
правдоподобия. Но, к счастью, оно наблюдается далеко не всегда. А вот так 
называемая инвариантность служит большим плюсом оценок максимального 
правдоподобия. Перед тем, чтобы начать обсуждать это, попробуем посчитать 
какую-либо оценку максимального правдоподобия.
\begin{problem}
	Пусть \((X_{1}, \dots, X_{n})\)~--- выборка из \(\mathcal{N}(\theta_{1}, 
	\theta_{2}^{2})\). Найти оценку максимального правдоподобия для 
	\((\theta_{1}, \theta_{2})\).
\end{problem}
\begin{proof}[Решение]
	Распишем функцию правдоподобия:
	\[
		p_{n}(x_{1}, \dots, x_{n}; \theta) = \frac{1}{(2\pi 
		\theta^{2})^{n/2}}\exp\left\{-\sum_{k = 1}^{n} \frac{(x_{k} - 
		\theta_{1})^{2}}{2\theta_{2}^{2}}\right\}.
	\]
	
	Теперь преобразуем степень определённым образом. Для этого заметим, что 
	\[
		(x_{k} - \theta_{1})^2 = (x_{1} - \overline{x})^2 + 2(\overline{x} - 
		\theta_{1})(x_{k} - \overline{x}) + (\overline{x} - \theta_{1})^2.
	\]
	
	Тогда
	\[
		\sum_{k = 1}^{n} \frac{(x_{k} - \theta_{1})^{2}}{2\theta_{2}^{2}} = 
		\frac{nS^{2}}{2\theta^{2}} + \frac{\overline{x} - 
		\theta_{1}}{\theta_{2}^2}\sum_{k = 1}^{n}(x_{k} - \overline{x}) + 
		\frac{n(\overline{x} - \theta_{1})^{2}}{2\theta_{2}^{2}} = 
		n\left(\frac{(\overline{x} - \theta_{1})^{2}}{2\theta_{2}^{2}} + 
		\frac{S^2}{2\theta_{2}^2}\right).
	\]
	
	Преобразуем дальше:
	\begin{align*}
		p_{n}(x_{1}, \dots, x_{n}; \theta) = 
		\frac{1}{(2\pi)^{n/2}}\exp\left\{-n\left(\frac{(\overline{x} - 
		\theta_{1})^{2}}{2\theta_{2}^{2}} + \frac{1}{2} 
		\left(\frac{S^2}{\theta_{2}^2} - 1\right) - 
		\ln\frac{S}{\theta_{2}}\right) - \frac{n}{2} - n\ln S\right\}.
	\end{align*}

	Теперь заметим, что максимизация этого выражения по \((\theta_{1}, 
	\theta_{2})\) есть ни что иное, как минимизация
	\[
		\psi(x_{1}, \dots, x_{n}; \theta) = \frac{(\overline{x} - 
		\theta_{1})^{2}}{2\theta_{2}^{2}} + \frac{1}{2} 
		\left(\frac{S^2}{\theta_{2}^2} - 1\right) - \ln\frac{S}{\theta_{2}}
	\]
	
	Рассмотрим функцию
	\[
		f(z) = \frac{1}{2}(z^2 - 1) - \ln{z}.
	\]
	
	Найдём её минимум. Для этого рассмотрим производную: \(f'(z) = z - 1/z\). 
	Понятно, что при \(z < 1\) эта функция убывает до нуля, а при \(z > 1\)~--- 
	возрастает. Тогда \(z = 1\) есть минимум этой функции. Осталось заметить, 
	что \(\psi(x_{1}, \dots, x_{n}; \theta)\) неотрицательна и равна нулю 
	только в том случае, когда \(\theta_{1} = \overline{x}\) и \(\theta_{2} = 
	S\). Тогда \(\theta^{*} = (\overline{X}, S)\) является оценкой 
	максимального правдоподобия для \(\theta = (\theta_{1}, \theta_{2})\).
\end{proof}
\begin{remark}
	Безусловно, это задачу можно было решить без всей этой экзотики. Например, 
	можно просто в лоб выписать систему уравнений правдоподобия и решить её. В 
	итоге мы бы получили ровно то же самое, но без лишней нервотрёпки.
\end{remark}

Теперь изменим параметр, который надо оценить: пусть \(\theta = (\theta_{1}, 
\theta_{2}^{2})\). Можно ли сказать, что \(\theta^{*} = (\overline{X}, S^2)\) 
является оценкой максимального правдоподобия? На самом деле можно~--- 
рассуждения для доказательства те же, только 
\[
	f(z) = \frac{1}{2}(z - 1 - \ln{z}).
\]

Поставим вопрос посложнее: а можно ли найти оценку максимального правдоподобия 
для \(\Phi((x_{0} - \theta_{1})/\theta_{2})\)? Для ответа на этот вопрос 
сформулируем теорему, которая даёт ответ на многие вопросы такого типа.
\begin{theorem}
	Пусть \(f: \Theta \mapsto F\)~--- некоторая биективная функция. Тогда, если 
	\(\theta^{*}\) есть оценка максимального правдоподобия для \(\theta\), то 
	\(f(\theta^{*})\)~--- оценка максимального правдоподобия для \(f(\theta)\).
\end{theorem}
\begin{proof}
	Восользуемся определением оценки максимального правдоподобия:
	\[
		p_{n}(\mathbf{x}; \theta^{*}) = \sup_{\theta \in \Theta} 
		p_{n}(\mathbf{x}; \theta) = \sup_{z \in F} p_{n}(\mathbf{x}; f^{-1}(z)) 
		= p_{n}(\mathbf{x}; f^{-1}(z^{*})).
	\]
	Тогда \(\theta^{*} = f^{-1}(z^{*})\) и \(z^{*} = f(\theta^{*})\).
\end{proof}

Теперь воспользуемся этой теоремой. Пусть \(\theta = (\theta_{1}, 
\theta_{2})\), а \(f(\theta) = (\Phi((x_{0} - \theta_{1})/\theta_{2}), 
\theta_{2})\). Несложно заметить, что \(f(\theta)\) есть биективная функция, 
переводящая \((-\infty, +\infty) \times [0, +\infty)\) в \([0, 1] \times [0, 
+\infty)\). Тогда
\[
	\left(\Phi\left(\frac{x_{0} - \overline{X}}{S}\right), S\right) \text{ есть 
	эффективная оценка для } \left(\Phi\left(\frac{x_{0} - 
	\theta_{1}}{\theta_{2}}\right), \theta_{2}\right).
\]

Это и даёт ответ на наш вопрос: да, оценка максимального правдоподобия для 
\(\Phi((x_{0} - \theta_{1})/\theta_{2})\) существует и она равна \(\Phi((x_{0} 
- \overline{X})/S)\).

Вообще, оценки максимального правдоподобия в основном являются состоятельными, 
асимптотически нормальными и асимптотически эффективными оценками. Вообще, 
асимптотические нормальность весьма полезна для построения доверительных 
интервалов, а эффективность~--- просто хорошее свойство. Если первые 
два типа оценок понятны, то для последнего нужно ввести определение:
\begin{definition}
	Будем называть оценку \(T_{n} = T_{n}(X_{1}, \dots, X_{n})\) 
	\emph{асимптотически эффективной}, если \(\eff{T_{n}} \to 1\) при \(n \to 
	\infty\).
\end{definition}

\subsection{Интервальные оценки}
\epigraph{"--* \dotsк сожалению, у вас очень серьезная болезнь. Из десяти 
	человек, заболевших ею, выживает только один. Но не беспокойтесь: вы 
	счастливчик! Вы останетесь жить, потому что обратились именно ко мне: 
	девять моих пациентов уже умерли от этой болезни.}

Теперь приступим к интервальным моментам. На самом деле, с точки зрения 
потребителя, да и со стороны приложений, точечные оценки~--- это какой-то 
промежуточный результат. Конечным же результатом служат проверка гипотез и 
интервальные оценки. Вообще, о чём идёт речь в интервальных оценках?

Представим себе, что анализируются финансовые данные, то есть у нас есть 
некоторый финансовый инструмент, и нас интересует его доходность. У нас есть 
\emph{исторические данные}: мы находимся в некотором моменте времени \(t\), и 
всё до этого момента времени известно. Теперь предположим, что доходность есть 
некоторая случайная величина \(X\). Далее для простоты сделаем неправдоподобное 
предположение: в любые два момента времени \(t_{1}\) и \(t_{2}\) доходности 
одинаково распределены и независимы.\footnote{Если смотреть на это с 
теоретической стороны, то может возникнуть сложность~--- таких случайных 
величин может быть континуум. Но на практике мы всегда орудуем с каким-то 
конечным набором, так что всё хорошо.} Понятно, что нас интересует не то, что 
было, а то, что будет. Иными словами, нас интересует поведение доходности на 
каком-то участке времени~--- та же средняя доходность \(\E{X}\). По значению 
средней доходности и определяется, что делать с инструментом: отбросить его или 
же использовать дальше. Теперь предположим, что доходность имеет распределение
\(\mathcal{N}(\theta, 1)\). Казалось бы, оценка \(\theta^{*} = \overline{X}\) 
всем хороша: несмещённая, состоятельная да и оптимальная вдобавок. Теперь 
возникает вопрос: а чему равна вероятность того, что мы попадём туда, куда 
надо? Правильно, нулю.
\[
	\Pr{\overline{X} = \theta} = 0.
\]

Не вдохновляет. Такая хорошая оценка, а мы почти наверное не попадаем в нужное 
значение. Казалось бы, после этого надо сразу же забросить статистику куда 
подальше и идти заниматься другими вещами. Но это для теоретиков. На практике 
же точное значение знать не обязательно, а порой и просто невозможно~--- 
достаточно знать его с какой-то точностью: да, точно в \(\theta\) мы не 
попадаем, но \(\theta^{*}\)~--- это <<почти>> \(\theta\). Забудьте про 0, лучше 
посмотрите на эту красоту: мы попадаем в маленький интервал с большой 
вероятностью!
\[
	\Pr{\theta \in (\overline{X} - \epsilon, \overline{X} + \epsilon)} > 0,99.
\]

Не устраивает? Допишем ещё одну девятку. Устроит? Более чем. Вообще говоря, 
такая задача для практики достаточно содержательна. Так что выбрасываем первое 
равенство (оно конечно, верное, но не вдохновляет) и берём второе.

\begin{definition}
	Пусть \(T_{1}(X_{1}, \dots, X_{n})\) и \(T_{2}(X_{1}, \dots, X_{n})\)~--- 
	некоторые оценки. Интервал \((T_{1}(X_{1}, \dots, X_{n}), T_{2}(X_{1}, 
	\dots, X_{n}))\) будем называть \emph{доверительным интервалом} параметра 
	\(\theta\) c \emph{коэффициентом доверия} \(\gamma\), если при всех 
	\(\theta \in \Theta\)
	\[
		\Pr{\theta \in (T_{1}(X_{1}, \dots, X_{n}), T_{2}(X_{1}, \dots, X_{n})} 
		\geq \gamma.
	\]
\end{definition}
\begin{remark}
	Вообще говоря, для полной красоты \(\theta\) нужно заменить на 
	\(\tau(\theta)\), но это не принципиально. На практике \(\geq\) обычно 
	заменяют на \(\approx\).
\end{remark}

Теперь поймём смысл определения. Допустим, что человек собрал какие-то данные 
(допустим, с той же биржи) и загнал их в компьютер. После вычислений он 
получил, что средняя доходность лежит в доверительном интервале \((0,12, 
0,83)\) с коэффициентом доверия \(\gamma = 0,95\). При этом человек готов 
вкладываться, если доходность не меньше, чем \(0,3\). И как ему быть?

Вообще фраза <<\(\theta\) лежит в интервале \((0,12, 0,83)\) с вероятностью 
\(0,95\)>> звучит несколько дико. Поясню, почему. Возьмём число 1. Понятно, что 
попадает на интервал \((0,5, 2)\) с вероятностью не меньше \(0,95\). Но если 
взять интервал \((2, 3)\), то единица там точно не лежит.

На самом деле ответ простой: верить в то, что искомая вероятность войдёт в 
интервал. Доверительный интервал говорит о следующем: допустим, у нас есть 
\(N\) выборок и по ним строятся эти доверительные интервалы. Теперь 
предположим, что \(N_{+}\) из них на самом деле содержат \(\theta\). Тогда 
\(N_{+}/N \geq \gamma\) при достаточно большом \(N\).

Теперь вопрос: что произойдёт с коэффициентом доверия, если увеличить интервал? 
Посмотрим на житейский пример. Допустим, что мы смотрим на погоду на сегодня по 
Москве. Нам говорят, что будет от пяти до семи градусов. Не потому, что Москва 
большая и температура в разных точках разная. Даже если мы хотим посмотреть 
погоду рядом с Кочновским проездом в полдень, или в пять вечера, например. Если 
вам говорят, что <<будет шесть градусов>>, то можно сказать <<ну не будет шесть 
градусов, а будет \(6,1\) градусов>>. Ну хорошо, будет от пяти до семи с 
коэффициентом надёжности \(0,8\).

Теперь сделаем сильное заявление: скажем, что \(0,8\) нам не нужно, а нужно 
\(0,2\). Понятно, что будет более точный прогноз~--- от \(5,5\) до \(6,5\) 
градусов. Если же выкрутить коэффициент доверия до 1, то получаем безошибочный 
прогноз погоды~--- \emph{завтра будет температура}. 