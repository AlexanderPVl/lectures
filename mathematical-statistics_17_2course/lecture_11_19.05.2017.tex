\section{Лекция 11 от 19.05.2017}
\subsection{Вероятности ошибок и критерии}
Вообще говоря, ошибки первого и второго рода есть случайные события, поэтому имеет смысл смотреть на их вероятности. Например, вероятность ошибки первого рода будем записывать в виде \(\Pr{H_{1} \given H_{0}}\). Такую запись можно понимать, как вероятность того, что мы приняли гипотезу \(H_{1}\) при условии того, что верна гипотеза \(H_{0}\). Аналогично, вероятность ошибки второго рода можно записать в виде \(\Pr{H_{0} \given H_{1}}\).\footnote{Формально эта запись некорректна, так как \(H_{0}\) и \(H_{1}\)~--- взаимоисключающие гипотезы (по определению) и если это понимать в буквальном смысле, то \(\Pr{H_{0} \given H_{1}} \equiv 0\). Правильнее писать \(\Pr{\text{приняли }H_{0} \given\text{верна } H_{1}}\). Но теоретики уже давно ушли из статистики, так как вероятность точно попасть в цель нулевая, так что будем писать так.}
	
Теперь попробуем построить какой-нибудь критерий. Пусть есть выборка \(X_{1}\) из выборки \(\mathcal{L}(X)\) и мы смотрим на следующие гипотезы:
\begin{gather*}
	H_{0} : \mathcal{L}(X) = \mathrm{U}(0, 1) \\
	H_{1} : \mathcal{L}(X) = \mathrm{U}(2, 3)
\end{gather*}

Вообще, этот пример чисто синтетический и в нем легко понять, какой критерий ввести: если \(X_{1} \in [0, 1]\), то принимаем \(H_{0}\), иначе же принимаем \(H_{1}\). Несложно понять, что этот критерий идеален в том смысле, что вероятность ошибок первого и второго рода нулевые:
\begin{gather}
	\Pr{H_{1} \given H_{0}} = \Pr{X_{1} \not\in [0, 1] \given X_{1} \sim \mathrm{U}(0, 1)} = 0 \\
	\Pr{H_{0} \given H_{1}} = \Pr{X_{1} \in [0, 1] \given X_{1} \sim \mathrm{U}(2, 3)} = 0
\end{gather}

Но, понятное дело, нулевые верояности ошибок первого и второго рода~--- непозволимая роскошь, которая почти не встречается. Рассмотрим такой пример: снова берётся выборка из одного элемента \(X_{1}\) с распределением \(\mathcal{L}(X)\). Теперь берутся две простые гипотезы:
\begin{gather*}
	H_{0} : \mathcal{L}(X) = \mathcal{N}(0, 1) \\
	H_{1} : \mathcal{L}(X) = \mathcal{N}(2, 1)
\end{gather*}

Теперь возьмём такой критерий: если \(X_{1} \leq 1\), то \(H_{1}\) принимается, иначе \(H_{0}\) отвергается. Посмотрим на вероятности ошибок:
\begin{gather*}
	\Pr{H_{1} \given H_{0}} = \Pr{X_{1} > 1 \given X_{1} \sim \mathcal{N}(0, 1)} = 1 - \Phi(1) \approx 0,159 \\
	\Pr{H_{0} \given H_{1}} = \Pr{X_{1} \leq 1 \given X_{1} \sim \mathcal{N}(2, 1)} = 1 - \Phi(1)
\end{gather*}

В данном случае у вероятностей ошибок есть хорошая визуализация:
\begin{center}
	\begin{tikzpicture}
	\begin{axis}[
	width=\textwidth,
	height=0.4\textwidth,
	xmin=-6,xmax=6,
	ymin=0,ymax=0.5,
	axis on top,
	legend style={legend cell align=right,legend plot pos=right,at={(0,1)},anchor=north west}] 
	\addplot[color=red,domain=-6:6,samples=100] {1/sqrt(2*pi)*exp(-x^2/2)};
	\addlegendentry{\(p_{\mathcal{N}(0, 1)}(x)\)}
	\addplot[color=blue,domain=-6:6,samples=100] {1/sqrt(2*pi)*exp(-(x - 
	2)^2/2)};
	\addlegendentry{\(p_{\mathcal{N}(2, 1)}(x)\)}
	\addplot+[mark=none,
	domain=1:6,
	samples=1000,
	pattern=north west lines,
	area legend,
	pattern color=red]{1/sqrt(2*pi)*exp(-x^2/2)} \closedcycle;
	\addlegendentry{Ошибка I рода}
	\addplot+[mark=none,
	domain=-6:1,
	samples=1000,
	pattern=north east lines,
	pattern color=blue,
	area legend]{1/sqrt(2*pi)*exp(-(x - 2)^2/2)} \closedcycle;    
	\addlegendentry{Ошибка II рода}
	\end{axis}
	\end{tikzpicture}
\end{center}

Вообще говоря, критерий~--- по которому мы определяем, какую из двух гипотез выбрать. Поэтому можно сказать, что критерий задаёт два неперескающихся множества \(X_{0}\) и \(X_{1}\) такие, что в них мы точно принимаем \(H_{0}\) и \(H_{1}\) соответственно. Множество \(X_{1}\) называется \emph{критической областью}. Теперь дадим одно определение:
\begin{definition}
	\(S\)-критерием называется критерий с критической областью \(S\).
\end{definition}

Но не всегда можно построить адекватный критерий, который точно будет выдавать ответ. Поэтому вводится ещё один вид критериев:
\begin{definition}
	\(\phi\)-критерием называется критерий, в котором гипотеза \(H_{0}\) отвергается с вероятностью \(\phi(Y)\), где \(Y = (y_{1}, \dots, y_{n})\)~--- реализация выборки.
\end{definition}

Несложно понять, что \(S\)-критерий~--- это \(\phi\)-критерий с \(\phi(Y) = 
\I\{Y \in S\}\). Если существует реализация \(Y\) такая, что\(\phi(Y) \in (0, 
1)\), то критерий называется \emph{рандомизированным}.

Дальше для удобства будем смотреть на параметрическое семейство: то есть, 
выборка \((X_{1}, \dots, X_{n})\) взята из распределения \(\mathcal{L}(X) \in 
\{\Pr_{\theta} \mid \theta \in \Theta\}\). Гипотезы тогда будут иметь вид
\begin{gather*}
	H_{0} : \theta \in \Theta_{0} \\
	H_{1} : \theta \in \Theta_{1} \\
	\Theta_{0} \cap \Theta_{1} = \emptyset, \text{ обычно } \Theta_{0} \cup 
	\Theta_{1} = \Theta
\end{gather*}

В статистике есть постулат, называемый \emph{общим принципом принятия решения}, 
который гласит: если в эксперименте наблюдается маловероятное при 
справедливости гипотезы \(H_{0}\) событие, то \(H_{0}\) не согласуется с 
данными (или противоречит им) и её отвергают. Поэтому обычно стараются сделать 
так:
\[
	\Pr{\text{приняли } H_{1} \given \text{верна } H_{0}} \leq \alpha
\]

Коэффициент \(\alpha\) называют \emph{значимостью критерия} и обычно 
приравнивают к \(0,05\).

Далее, обычно не получается сделать сумму вероятностей ошибок обоих родов сколь 
угодно малой.\footnote{Ульянов на лекции сказал, что обычно не получается 
уменьшить вероятности обеих ошибок. Вообще, это утверждение, конечно же, 
неверно~--- можно сначала взять плохой критерий, а потом нормальный (в качестве 
упражнения приведите контрпример).} Почему это так? Понятное дело, что это 
верно не всегда~--- выше мы приводили пример, в котором обе вероятности 
нулевые. Но там был достаточно синтетический случай в том плане, что области 
значения соответствующих случайных величин не пересекались. А что произойдёт, 
если их области пересекаются?

В таком случае можно посмотреть на два случая: если в пересечении есть 
множества, в которых точно принимается или же отвергается гипотеза и если таких 
нет. В первом случае есть ненулевая вероятность того, что можно попасть не в то 
множество и допустить ошибку. То, что второй случай точно будет давать 
ненулевую вероятность, достаточно очевидно.

Из-за этого принято фиксировать уровень значимости и пытаться минимизировать 
вероятность ошибки второго рода. Но почему? Для этого вводится понятие 
\emph{мощности} критерия.
\begin{definition}
	Мощность \(\phi\)-критерия равна 
	\[
		W(\theta, \phi) = \E_{\theta}[\phi(X)] = \int\limits_{\R^{n}} 
		\phi(\mathbf{x})p_{n}(\mathbf{x}; \theta)\diff\mathbf{x}.
	\]
\end{definition}

Теперь возьмём две простых параметрических гипотезы \(H_{0} : \theta = 
\theta_{0}\) и \(H_{1} : \theta = \theta_{1}\) и построим для них 
\(S\)-критерий. Тогда
\begin{gather*}
	W(\theta_{0}, \phi) = \E_{\theta_{0}}[\I\{X \in S\}] = \Pr{X \in S \given 
	H_{0}} = \Pr{H_{1} \given H_{0}} = \alpha. \\
	W(\theta_{1}, \phi) = \Pr{X \in S \given H_{1}} = \Pr{H_{1} \given H_{1}} = 
	1 - \Pr{H_{0} \given H_{1}}.
\end{gather*}

Величину \(1 - \Pr{H_{0} \given H_{1}}\) называют \emph{мощностью} критерия. 

\subsection{Лемма Неймана-Пирсона}
Теперь вопрос: как максимизировать мощность критерия при заданном уровне 
значимости и возможно ли это? Если пользоваться только \(S\)-критериями, то 
ответ отрицательный. Однако, если добавить в арсенал \(\phi\)-критерии, то 
можно найти критерий максимальной мощности. Об этом гласит следующая
\begin{lemma}[Нейман, Пирсон]
	Пусть \(\alpha \in (0, 1)\)~--- фиксированный уровень значимости (ещё его 
	называют размером критерия). Тогда критерий
	\[
		\phi^{*}(Y) = \begin{cases}
		1,& p_{n}(Y; \theta_{1}) > c_{\alpha}p_{n}(Y; \theta_{1}) \\
		\epsilon_{\alpha},& p_{n}(Y; \theta_{1}) = c_{\alpha}p_{n}(Y; 
		\theta_{1}) \\
		0,& p_{n}(Y; \theta_{1}) < c_{\alpha}p_{n}(Y; \theta_{1})
		\end{cases}
	\]
	где \(c_{\alpha}\) и \(\epsilon_{\alpha}\)~--- решения уравнения 
	<<вероятность ошибки первого рода для этого критерия равна \(\alpha\)>>: 
	\[
		\Pr{p_{n}(Y; \theta_{1}) > c_{\alpha}p_{n}(Y; \theta_{1})} + 
		\epsilon_{\alpha}\Pr{p_{n}(Y; \theta_{1}) = c_{\alpha}p_{n}(Y; 
		\theta_{1})} = \alpha
	\]
	является наиболее мощным критерием для заданного уровня значимости 
	\(\alpha\): для любого \(\phi\)-критерия \(W(\theta, \phi^{*}) \geq 
	W(\theta, \phi)\).
\end{lemma}

Заметим, что в критерии пропускаются случаи \(\alpha = 0\) и \(\alpha = 1\). Но 
с ними всё просто: \(\phi(Y) = \alpha\) являются самыми мощными критериями в 
данном случае.

Рассмотрим пример её применения.
\begin{problem}
	Пусть \((X_{1}, \dots, X_{n})\)~--- выборка из нормального распределения 
	\(\mathcal{L}\). Теперь введём две гипотезы
	\begin{gather*}
		H_{0} : \mathcal{L}(X) = \mathcal{N}(\theta_{0}, 1) \\
		H_{1} : \mathcal{L}(X) = \mathcal{N}(\theta_{1}, 1), \theta_{1} > 
		\theta_{0}
	\end{gather*}
	Найти наиболее мощный критерий размера \(\alpha\).
\end{problem}
\begin{proof}[Решение]
	Рассмотрим отношение функций правдоподобия:
	\[
		\frac{p_{n}(X; \theta_{1})}{p_{n}(X; \theta_{1})} = 
		\exp\left\{-\frac{1}{2}\sum_{k = 1}^{n}\left((X_{k} - \theta_{1})^{2} - 
		(X_{k} - \theta_{0})^{2}\right)\right\} > c_{\alpha}
	\]
	Тогда
	\[
		\frac{\theta_{1} - \theta_{0}}{2}\sum_{k = 1}^{n}(2X_{k} - \theta_{1} - 
		\theta_{0}) > \ln{c_{\alpha}} \implies 2n\overline{X} - n(\theta_{0} + 
		\theta_{1}) > \frac{2\ln{c_{\alpha}}}{\theta_{1} - \theta_{0}}
	\]
	Последний штрих:
	\[
		\overline{X} > \frac{\ln{c_\alpha}}{n(\theta_{1} - \theta_{0})} + 
		\frac{\theta_{0} + \theta_{1}}{2} = c'_{\alpha}
	\]
	
	Теперь вспомним, что обе функции распределения абсолютно непрерывны, так 
	что вероятность равенства в лемме нулевая. Следовательно, без ограничения 
	общности приравняем \(\epsilon_{\alpha}\) к единице. Теперь найдём 
	\(c_{\alpha}\). Заметим, что если верна \(H_{0}\), то \(\overline{X} \sim 
	\mathcal{N}(\theta_{0}, 1/n)\). Следовательно,
	\[
		\sqrt{n}(\overline{X} - \theta_{0}) \sim \mathcal{N}(0, 1) \implies 
		\overline{X} > c'_{\alpha} \iff \sqrt{n}(\overline{X} - \theta_{0}) > 
		\sqrt{n}(c'_{\alpha} - \theta_{0})
	\]
	
	Вероятность ошибки первого рода будет равна
	\[
		\Phi(\sqrt{n}(c'_{\alpha} - \theta_{0})) = \alpha \implies c'_{\alpha} 
		= \theta_{0} + \frac{\Phi^{-1}(\alpha)}{\sqrt{n}}
	\]
	
	Тем самым получили критерий: Если \(\overline{X} > \theta_{0} + 
	\frac{\Phi^{-1}(\alpha)}{\sqrt{n}}\), то \(H_{0}\) отвергается.
\end{proof}

Вообще говоря, мы получили так называемый \emph{равномерно наиболее мощный 
критерий}, то есть он является наиболее мощным вне зависимости от значений 
\(\theta_{0}\) и \(\theta_{1}\).