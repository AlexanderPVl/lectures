\section{Лекция 3 от 10.03.2017}
\subsection{Оптимальные оценки}
Рассмотрим некоторую выборку \((X_{1}, \dots, X_{n})\) из распределения 
\(\{\Pr_{\theta} \mid \theta \in \Theta\}\). Обычно полагается, что \(\Theta 
\subseteq \R^{d}\). Параметр может быть как одномерным (например, параметр 
экспоненциального распределения), так и многомерным (например, матожидание и 
дисперсия нормального распределения). Как обычно, возникает вопрос: как 
построить точечную оценку \(\theta^{*} = \theta^{*}(X_{1}, \dots, X_{n})\) 
такую, что она была <<наилучшей>> оценкой \(\theta\)?

Что означает это злополучное слово <<наилучшее>>? Для этого на данный момент 
было выделено два свойства оценок, которые обычно проверяются у оценок: 
несмещённость и состоятельность.

Как известно, несмещённость означает, что матожидание оценки совпадает с 
значением параметра, а состоятельность означает сходимость оценки к параметру 
по вероятности. Но есть несколько проблем. Например, несмещённые оценки
\begin{enumerate}
	\item не единственны,
	\item могут вообще не существовать,
	\item могут быть бессмысленными,
	\item не инвариантны относительно преобразований параметра.
\end{enumerate}

Аналогичные вещи можно сказать и про состоятельные оценки. Действительно, они 
не единственны. Пусть \(T_{n} = T_{n}(X_{1}, \dots, X_{n})\)~--- какая-нибудь 
состоятельная оценка. Возьмём последовательность \(\phi_{n} = \phi_{n}(X_{1}, 
\dots, X_{n})\), которая по вероятности сходится к нулю. Тогда по лемме Слуцкого
\(T_{n} + \phi_{n} \prto \theta\). Так же, как и с несмещёнными оценками, 
состоятельные оценки могут быть бессмысленными, то есть множество значений 
оценки не совпадает с множеством значений параметра.

Обычно проверяются эти два свойства, но это не сильно убеждает: пусть есть 
несмещённая и состоятельная оценка. Можно ли назвать её наилучшей? 
Непонятно.

Давайте добавим к несмещённости минимальность дисперсии. Как вы помните, 
дисперсия есть величина разброса значений относительно среднего. Тогда мы 
получаем достаточно приятную вещь: в среднем мы попадаем туда, куда надо, да и 
разброс минимален. Это условие даёт так называемую оптимальную оценку.
\begin{definition}
	Оценка \(\theta^{*} = \theta^{*}(X_{1}, \dots, X_{n})\) называется 
	\emph{оптимальной}, если она несмещённая и для любой несмещённой оценки \(T 
	= T(X_{1}, \dots, X_{n})\) \(\D{T} \geq \D{\theta^{*}}\) для любого 
	\(\theta \in \Theta\).
\end{definition}

Условие на то, что неравенство должно быть выполнено для любого \(\theta \in 
\Theta\), достаточно важно. Понятно, что оценки зависят от \(\theta\) (и от 
\(n\) тоже), и может оказаться так, что они просто не сравнимы, так как на 
одних значениях \(\theta\) будет больше \(\D{\theta^{*}}\), а на других~--- 
\(\D{T}\).

Стоит сказать, что оптимальной оценки может и не быть (например, когда нет 
несмещённых оценок). Но если они есть, то их немного~--- примерно одна. Докажем 
это.
\begin{theorem}
	Если существует оптимальная оценка, то она единственна с точностью до 
	равенства почти наверное.
\end{theorem}
\begin{proof}
	Пусть \(T_{1} = T_{1}(X_{1}, \dots, X_{n})\) и \(T_{2} = T_{2}(X_{1}, 
	\dots, X_{n})\)~--- оптимальные оценки c дисперсией \(\sigma^{2}\). 
	Посчитаем \(\D{T_{1} + T_{2}}\):\footnote{На этой тривиальной формуле 
	построена теория финансовых портфелей. В финансовых портфелях дисперсия 
	выступает в качестве меры риска. Если вы вкладываете в разнонаправленные 
	финансовые инструменты, то ковариация становится отрицательной и дисперсия 
	суммы становится меньше суммы дисперсий. Именно в этом и состоит идея 
	портфелей: давайте мы сделаем из рискованных активов нечто суммарное, и 
	риск суммы станет меньше.}
	\[
		\D{T_{1} + T_{2}} = \cov(T_{1} + T_{2}, T_{1} + T_{2}) = \D{T_{1}} + 
		\D{T_{2}} + 2\cov(T_{1}, T_{2}).
	\]
	
	Теперь вспомним неравенство Коши-Буняковского:
	\[
		\D{T_{1}} + \D{T_{2}} + 2\cov(T_{1}, T_{2}) \leq \D{T_{1}} + \D{T_{2}} 
		+ 2\sqrt{\D{T_{1}}\D{T_{2}}} = 4\sigma^{2}.
	\]
	
	Однако заметим, что \(T = (T_{1} + T_{2})/2\) является несмещённой оценкой, 
	поэтому \(\D{T} \geq \sigma^{2}\). Отсюда получаем, что 
	\[
		2\sigma^{2} + 2\cov(T_{1}, T_{2}) = 4\sigma^{2} \implies \rho(T_{1}, 
		T_{2}) = 1.
	\]
	
	Как известно, коэффициент корреляции равен единице тогда и только тогда, 
	когда случайные величины линейно зависимы почти наверное: \(T_{1} 
	\overset{\text{п.н.}}{=} aT_{2} + b\). Осталось посчитать \(a\) и \(b\). Из 
	несмещённости следует, что \(\theta = a\theta + b\). Теперь расмотрим 
	ковариацию:
	\[
		\cov(T_{1}, T_{2}) = \E{(T_{1} - \E{T_{1}})(T_{2} - \E{T_{2}})} = 
		\E{(T_{1} - \theta)(T_{2} - \theta)}.
	\]
	
	Заменим \(T_{1}\) на \(aT_{2} + b\) и воспользуемся тем, что \(a\theta = 
	\theta - b\):
	\[
		\cov(T_{1}, T_{2}) = \E{(aT_{2} - \theta + b)(T_{2} - \theta)} = 
		a\E{(T_{2} - \theta)^{2}} = a\sigma^{2}.
	\]
	
	Но мы уже посчитали, что \(\cov(T_{1}, T_{2}) = \sigma^{2}\). Отсюда сразу 
	получаем, что \(a = 1\), \(b = 0\) и \(T_{1} \overset{\text{п.н.}}{=} 
	T_{2}\).
\end{proof}

\subsection{Асимптотически нормальные оценки}
Теперь рассмотрим ещё один вид оценок~--- так называемые асимптотически 
нормальные оценки. Их можно задать двумя способами:
\begin{definition}
	Оценка \(\theta^{*}_{n} = \theta^{*}_{n}(X_{1}, \dots, X_{n})\) называется 
	\emph{асимптотически нормальной} с параметрами \(\{a_{n} \mid n \in \N\}\) 
	и \(\{b_{n} \mid n \in \N\}\), если
	\[
		\frac{\theta^{n}_{n} - a_{n}}{b_{n}} \dto \mathcal{N}(0, 1).
	\]
\end{definition}
\begin{definition}
	Оценка \(\theta^{*}_{n} = \theta^{*}_{n}(X_{1}, \dots, X_{n})\) называется 
	\emph{асимптотически нормальной} оценкой \(\theta\) с параметром \(b\), если
	\[
		\sqrt{n}(\theta^{*}_{n} - \theta) \dto \mathcal{N}(0, b).
	\]
\end{definition}

Вообще, зачем они нужны? Например, они нужны для построения асимптотических 
доверительных интервалов или же для проверки гипотез. 
\begin{exercise}
	Пусть \(\theta = \E{X}\), а \((X_{1}, \dots, X_{n})\)~--- выборка из 
	распределения \(\mathcal{L}(X)\). С помощью центральной предельной теоремы 
	покажите, что \(\overline{X}\) является асимптотически нормальной оценкой 
	\(\theta\) с коэффициентом \(\D{X}\).
\end{exercise}

Вообще, можно показать, что все выборочные моменты являются асимптотически 
нормальными оценками при условии, что условная случайная величина имеет 
достаточное число моментов.

\subsection{Метод моментов. Функция правдоподобия}
Ранее мы ввели различные виды оценок. Но как их строить? Один из методов 
называется \emph{методом моментов}. В чём он состоит?

Допустим, что у нас есть выборка \((X_{1}, \dots, X_{n})\) из \(\mathcal{L}(X) 
\in \{\Pr_{\theta} \mid \theta \in \Theta\}\), где \(\Theta \subseteq \R^{k}\). 
Теперь предположим, что у 
случайной величины \(X\) есть первые \(k\) моментов \(\mu_{1} = \E{X}, \dots, 
\mu_{k} = \E{X^{k}}\). Понятно, что они являются функциями от \(\theta\): 
\(\mu_{i} = \mu_{i}(\theta)\). Тогда заменим теоретические моменты на 
выборочные, а параметр заменим на его оценку:
\[
	\mu_{i}(\theta^{*}) = m_{i} = \overline{X^{i}}, \quad i \in \{1, 2, \dots, 
	k\}.
\]

Теперь предположим, что эта система уравнений имеет однозначное решение 
\(\theta^{*} = (\theta^{*}_{1}, \dots, \theta^{*}_{k})\), где \(\theta^{*}_{i} 
= \phi_{i}(X_{1}, \dots, X_{n})\). Тогда \(\theta^{*}\) является оценкой 
\(\theta\). Можно показать, что если все \(\phi_{i}\) непрерывны, то полученная 
оценка состоятельна. А теперь посмотрим, как его применять.

\begin{problem}
	Пусть \((X_{1}, \dots, X_{n})\)~--- выборка из \(\mathrm{Bin}(m, p)\). 
	Оцените \(m\) и \(p\) с помощью метода моментов.
\end{problem}
\begin{proof}[Решение]
	Распишем первые два момента и выразим \(m\) и \(p\) через них:
	\[
		\begin{cases}
		\E{X} = mp \\
		\E{X^{2}} = mp(1 - p) + m^{2}p^{2}
		\end{cases}
		\implies 
		\begin{cases}
		p = \frac{\E{X} + (\E{X})^2 - \E{X^2}}{\E{X}} \\
		m = \frac{(\E{X})^2}{\E{X} + (\E{X})^2 - \E{X^2}}
		\end{cases}
	\]

	Тогда по методу моментов получаем, что
	\[
		p = \frac{m_{1} + m_{1}^{2} - m_{2}}{m_{1}}, \quad m = 
		\frac{m_{1}^{2}}{m_{1} + m_{1}^{2} - m_{2}}. \qedhere
	\]
\end{proof}

Теперь введём понятие \emph{функции правдоподобия}~--- она будет нужна для 
того, чтобы выбирать <<наилучшие>> оценки. Её мы введём для двух случаев: 
дискретного и абсолютно непрерывного. 
\begin{definition}
	Пусть \((X_{1}, \dots, X_{n})\)~--- выборка из \(\mathcal{L}(X) \in 
	\{\Pr_{\theta} \mid \theta \in \Theta\}\). Тогда \emph{функцией 
	правдоподобия} будем называть
	\[
		p_{n}(x_{1}, \dots, x_{n}; \theta) = \prod_{k = 1}^{n}
		\begin{cases}
		\Pr{X = x_{i}}, & \mathcal{L}(X)\text{ дискретно} \\
		p_{X}(x_{i}), & \mathcal{L}(X)\text{ абсолютно непрерывно}
		\end{cases}
	\]
\end{definition}