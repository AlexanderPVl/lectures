\section{Лекция 12 от 26.05.2017}
Лемма Неймана-Пирсона для двух простых гипотез примечательна следующим:
при фиксированном уровне значимости (размера) $\alpha$ критерия она
позволяет построить критерий наибольшей мощности. Также она позволяет
строить равномерно наиболее мощные критерии. То есть при сложной
альтернативной гипотезе критерий, построенный по лемме Неймана-Пирсона
либо не зависит от альтернативной гипотезы, либо зависит в малой
степени.
\subsection{Доказательство леммы Неймана-Пирсона}
Пусть $Y = (X_1, \ldots, X_n)$ --- выборка из распределения 
$\mathcal{L}(X)$ с распределением, зависящим от одномерного параметра
$\theta$. Обе гипотезы, основная $H_0$ и альтернативная $H_1$ являются
простыми. Для произвольного $c > 0$ определим следующую функцию:
\[
    g(c) = \Pr\big(p_1(Y) \geqslant c p_0(Y)\ |\ H_0\big) =
    \Pr_0\big(p_1(Y) \geqslant c p_0(Y)\big).
    \]
Заметим, что
\[
    1 - g(c) = \Pr_0\left( \frac{p_1(Y)}{p_0(Y)} < c \right)
    \]
есть функция распределения некоторой положительной случайной величины.
Отсюда получаем следующие свойства:
\begin{enumerate}
    \item Как функция распределения, $1 - g(c)$ имеет следующие
        пределы:
        \[
            1 - g(c) \to
            \begin{cases}
                1, & c \to +\infty,\\
                0, & c \to 0+.
            \end{cases}
            \quad \Longrightarrow \quad
            g(c) \to
            \begin{cases}
                1, & c \to 0,\\
                0, & c \to +\infty.
            \end{cases}
            \]
    \item $g(c)$ есть невозрастающая функция.
    \item $g(c)$ непрерывна слева.
\end{enumerate}
Пусть фиксирован уровень значения $\alpha \in (0,\ 1)$. Для начала
явно найдем $c_\alpha$ и $\epsilon_\alpha$. Рассмотрим, как может
выглядеть график $g(c)$, учитывая вышеописанные свойства. $\alpha$
может попасть на участок убывания функции $g$, на участок
постоянства и на участок разрыва.
\begin{center}
    \begin{tikzpicture}
        \draw[->] (0,0) -- (10.25,0) node[right] {$c$};
        \draw[->] (0,0) -- (0,5) node[above] {$g(c)$};
        \draw (0,0) node[left] {$0$};
        \draw[scale=1,domain=0:2,smooth,variable=\c,blue] plot
        ({\c},{4 - 0.25*\c*\c});
        \draw[scale=1,domain=2:4,smooth,variable=\c,blue] plot
        ({\c},{3});
        \draw[scale=1,domain=4:5,smooth,variable=\c,blue] plot
        ({\c},{-\c*\c+8*\c-13});
        \draw[scale=1,domain=5:10,smooth,variable=\c,blue] plot
        ({\c},{9 / \c - 4 / 5});
        \draw[dashed] (0,3.5) node[left] {$\alpha_1$} -- (1.41,3.5);
        \draw[dashed] (1.41,0) node[below] {$c_{\alpha_1}$} --
        (1.41,3.5);
        \draw[dashed] (0,3) node[left] {$\alpha_2$} -- (2,3);
        \draw[dashed] (3,0) node[below] {$c_{\alpha_2}$} --
        (3,3);
        \draw[dashed] (0,1.5) node[left] {$\alpha_3$} -- (5,1.5);
        \draw[dashed] (5,0) node[below] {$c_{\alpha_3}$} --
        (5,1);
    \end{tikzpicture}
\end{center}

\begin{enumerate}
    \item $\alpha_1$ попала на участок строгой монотонности. Тогда
        \[
            c_{\alpha_1}:\ g(c_{\alpha_1}) = \alpha_1,
            \qquad \epsilon_{\alpha_1} = 0.
            \]
    \item $\alpha_2$ попала на участок постоянства. Тогда
        $c_{\alpha_2}$ есть произвольное число с участка постоянства
        функции $g$, где $g(c) = \alpha_2$. В этом случае также
        $\epsilon_{\alpha_2} = 0$.
    \item $\alpha_3$ попала на участок разрыва. Тогда числа выбираются
        следующим образом:
        \[
            c_{\alpha_3}:\ g(c_{\alpha_3}) \geqslant \alpha_3 >
            g(c_{\alpha_3} + 0), \qquad \epsilon{\alpha_3} =
            \frac{\alpha_3 - g(c_{\alpha_3}+0)}{g(c_{\alpha_3}) - 
            g(c_{\alpha_3}+0)}.
            \]
\end{enumerate}
\remark{если выборка взята из абсолютно непрерывного распределения,
получается $S$-критерий}

Будем считать, что распределение абсолютно непрерывно с точкой
разрыва (случай дискретного распределения аналогичен). Докажем, что
$\E_0 \phi^*(Y) = \alpha$, то есть что уровень значимости
действительно равен $\alpha$.
\[
    \E_0 \phi^*(Y) = \idotsint\limits_{\R^n} \phi^*(y)\ p_0(y)\ dy =
    \idotsint\limits_{p_1(y) > c_\alpha p_0(y)} p_0(y)\ dy +
    \epsilon_\alpha\idotsint\limits_{p_1(y) = c_\alpha p_0(y)} 
    p_0(y)\ dy.
    \]
Если бы в первом интеграле область интегрирования была $p_1(y)
\geqslant c_\alpha p_0(y)$, то мы бы получили в точости $g(c_\alpha)$.
Тогда добавим и вычтем интеграл единицы по области $p_1(y) = c_\alpha
p_0(y)$. Получим
\[
    g(c_\alpha) + (\epsilon_\alpha - 1)
    \idotsint\limits_{p_1(y) = c_\alpha p_0(y)} p_0(y)\ dy = 
    g(c_\alpha) + \frac{\alpha - g(c_\alpha)}{g(c_\alpha) -
    g(c_\alpha + 0)}\underbrace{\big( g(c_\alpha) - g(c_\alpha + 0)
    \big)}_{\Pr_0(p_1(Y) = c_\alpha p_0(Y))} = \alpha.
    \]

Докажем, что получившийся критерий имеет наибольшую мощность. Пусть
$\phi(y)$ --- другой $\phi$-критерий. Тогда
\[
    \idotsint\limits_{\R^n} \underbrace{\big( \phi^*(y) - \phi(y)
    \big) \big( p_1(y) - c_\alpha p_0(y) \big)}_{f(y)}\ dy = 
    \underbrace{\idotsint\limits_{y:\ \phi^*(y) > \phi(y)}
    f(y)\ dy}_{I_1} + \underbrace{\idotsint\limits_{y:\ \phi^*(y) <
    \phi(y)} f(y)\ dy}_{I_2}.
    \]

Для $I_1$ получаем, что при $\phi^*(y) > \phi(y) \geqslant 0$ по
построению $\phi^*(y)$ выполнено $p_1(y) \geqslant c_\alpha p_0(y)$,
поскольку именно в этой зоне $\phi^*(y) > 0$. Но тогда в $I_1$ мы
интегрируем неотрицательную функцию, а значит, $I_1 \geqslant 0$.
Аналогично для $I_2$ получаем, что при $\phi^*(y) < \phi(y) \leqslant
1$, то есть $p_1(y) \leqslant c_\alpha p_0(y)$, выполнено $I_2
\geqslant 0$. Складывая, $I_1 + I_2 \geqslant 0$. Заметим теперь, что
исходный интеграл при раскрытии скобок с учетом неотрицательности
переписывается в следующим виде:
\[
    \E_1 \phi^*(Y) - \E_1 \phi(Y) \geqslant c_\alpha \big(
    \underbrace{\E_0 \phi^*(Y)}_{= \alpha} - \E_0 \phi(Y) \big).
    \]
То есть для любого $\phi$-критерия такого, что $\E_0 \phi(Y) \leqslant
\alpha$, выполнено $\E_1 \phi^*(Y) \geqslant \E_1 \phi(Y)$. Таким
образом, мы по заданному $\alpha$ явно построили критическую функцию
для $\phi$-критерия, доказали, что полученный критерий имеет размер
$\alpha$, а его мощность не меньше мощности любого критерия с
уровнем значимости не более $\alpha$. Лемма полностью доказана.

\subsection{Применение леммы Неймана-Пирсона}
Пусть выборка $Y$ из распределения Бернулли с неизвестным 
параметром $\theta$. То есть 
\[
    X_i =
    \begin{cases}
        1, & p = \theta,\\
        0, & p = 1 - \theta.
    \end{cases}
    \]
Пусть основная гипотеза $H_0$ есть $\theta = \theta_0$, а
конкурирующая $H_1$ --- $\theta = \theta_1$. Для определенности
будем считать $\theta_1 > \theta_0$.

Несмотря на простоту данной схемы, она широко применима. Например,
если имеются два метода лечения, а $\theta_0,\ \theta_1$ ---
вероятности выздоровления у двух методов, то данная схема описывает
выбор наилучшего метода.

Согласно лемме Неймана-Пирсона наиболее мощный критерий мы должны
искать через отношение функций правдоподобия. Выпишем его:
\[
    \frac{p_1(y)}{p_0(y)} = \Big( \underbrace{\frac{\theta_1}{1
    - \theta_1} \frac{1-\theta_0}{\theta_0}}_{A} \Big)^{\sum
    x_i} \underbrace{\left( \frac{1-\theta_1}{1-\theta_0}
    \right)^n}_{B}.
    \]
Нас интересует, когда это отношение больше некоторой константы
$c_\alpha$. Заметим, что $B$ не зависит от выборки и $B>0$.
Поэтому мы имеем право перенести этот множитель в правую часть,
получив некоторую константу $c_\alpha'$. Далее прологарифмируем
полученное неравенство (логарифм --- монотонная функция):
\[
    \left[ \sum_{i=1}^n x_i \right] \ln{A} > c_\alpha'.
    \]
Принимая во внимание возрастание функции $\theta / (1 - \theta)$
по $\theta$, получаем, что $A > 1$, значит, можно поделить на
логарифм от $A$. В итоге для некоторой константы $c_\alpha''$ мы
получим следующий критерий:
\[
    \overline{X} > c_\alpha'' \qquad \text{или} \qquad
    \sum_{i=1}^n X_i > c_\alpha''.
    \]
Таким образом, при большой доле единиц нужно отвергать гипотезу
$H_0$, что довольно естественно с учетом $\theta_1 > \theta_0$.

Теперь надо понять, как найти $c_\alpha''$. Заметим, что
\[
    \Pr\left(\sum_{i=1}^n X_i > c_\alpha''\ |\ H_0\right) = \alpha.
    \]
На самом деле в лемме случай <<больше>> и <<больше либо равно>>
различаются, но мы перейдем к нормальной случайной величине, где
это не важно. Итак, согласно центральной предельной теореме,
\[
    \Pr\left(\sum X_i > c_\alpha''\ |\ H_0\right) = \Pr\left(
    \frac{\sum X_i - n\theta_0}{\sqrt{n\theta_0(1-\theta_0)}} >
    \frac{c_\alpha'' - n\theta_0}{\sqrt{n\theta_0(1-\theta_0)}}\
    \Big|\ H_0\right) \approx \Pr(Z > z_{1-\alpha}) = \alpha,
    \]
где $Z$ есть стандартная нормальная случайная величина, $z_{1-\alpha}$
--- ее квантиль порядка $1-\alpha$. При этом
\[
    z_{1-\alpha} = \frac{c_\alpha'' - n\theta_0}{\sqrt{n\theta_0
    (1-\theta_0)}}.
    \]
Отсюда находим $c_\alpha'' = n\theta_0 + z_{1-\alpha}\sqrt{n\theta_0
(1-\theta_0)}$. То есть именно с этим значением надо сравнивать
сумму $X_i$. Найдем мощность данного критерия, то есть вероятность
ошибки 2 рода. Снова воспользуемся центральной предельной теоремой:
\begin{multline*}
    \beta = \Pr(H_0\ |\ H_1) = \Pr\left(\sum_{i=1}^n X_i \leqslant
    c_\alpha''\ |\ H_1 \right) = \Pr\left( \frac{\sum X_i-n\theta_1}{ 
    \sqrt{n\theta_1(1-\theta_1)}} \leqslant \frac{c_\alpha'' -
    n\theta_1}{\sqrt{n\theta_1(1-\theta_1)}}\ \Big|\ H_1 \right)
    \approx \\\\ \approx \Phi\left( \frac{n(\theta_0-\theta_1) +
    z_{1-\alpha} \sqrt{n\theta_0(1-\theta_0)}}{\sqrt{n\theta_1(1
    \theta_1)}} \right) \quad \underset{n \to \infty}{\longrightarrow}
    \quad 0.
\end{multline*}
Заметим, что здесь мы, во-первых, производили нормировку по $\theta_1$,
поскольку предполагается, что выполнена гипотеза $H_1$. Во-вторых,
здесь вместо $c_\alpha''$ мы подставили найденное значение. Стремление
к нулю вытекает из стремления к $-\infty$ аргумента функции
распределения. Действительно, $\theta_0 < \theta_1$, а старшее по
порядку $n$ слагаемое умножается на $(\theta_0 - \theta_1)$.

Итак, можно сделать следующий вывод: при увеличении объема выборки
мы можем добиться сколь угодно малой вероятности ошибки 2 рода.
Важно, что это можно сделать только при изменяемом объеме выборки.
Также можно заметить, что при малых значениях $n$ получить необходимые
значения ошибок можно, если $\theta_0 - \theta_1$ не слишком мало по
модулю. Значит, если гипотезы достаточно близки, то при малом объеме
выборки различить гипотезы с разумными вероятностями ошибок сложно.

Более того, для фиксированных $\alpha,\ \beta$ можно указать
наименьший объем выборки $n$ так, чтобы критерий имел вероятности
ошибок 1-го и 2-го рода $\alpha$ и $\beta$ соответственно. В этом
случае необходимо, чтобы аргумент функции $\Phi$ в последнем
равенстве был равен $\beta$. Тогда можно выразить $n$:
\[
    n \geqslant \left( \frac{z_{1-\alpha} \sqrt{\theta_0(1-\theta-0)}
    + z_{1-\beta}\sqrt{\theta_1(1-\theta_1)}}{\theta_1 - \theta_0}
    \right)^2.
    \]
Снова видим, что при близких значениях $\theta_0$ и $\theta_1$ объем
выборки оказывается довольно велик.
